{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "989a5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09a494a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I am going to define single head attention from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a7a903",
   "metadata": {},
   "source": [
    "<h2><center>Single Head Self Attention<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e587349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS:\n",
    "sequence_length = 4\n",
    "embedding_dimension = 8\n",
    "# I defined hyperparameters for the attention mechanism.\n",
    "# I need sequence length, embedding dimension, head dimension.\n",
    "# Each word should have many different concepts, so embedding dimension is 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "447b63f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embeddings:\n",
      "(4, 8)\n",
      "[[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788\n",
      "   0.95008842 -0.15135721]\n",
      " [-0.10321885  0.4105985   0.14404357  1.45427351  0.76103773  0.12167502\n",
      "   0.44386323  0.33367433]\n",
      " [ 1.49407907 -0.20515826  0.3130677  -0.85409574 -2.55298982  0.6536186\n",
      "   0.8644362  -0.74216502]\n",
      " [ 2.26975462 -1.45436567  0.04575852 -0.18718385  1.53277921  1.46935877\n",
      "   0.15494743  0.37816252]]\n"
     ]
    }
   ],
   "source": [
    "# TOKEN EMBEDDINGS:\n",
    "token_embeddings = np.random.randn(sequence_length, embedding_dimension)\n",
    "print(\"token_embeddings:\")\n",
    "print(token_embeddings.shape)\n",
    "print(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5d35d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weight matrices shapes:\n",
      "W_q shape: (8, 8)\n",
      "[[-0.88778575 -1.98079647 -0.34791215  0.15634897  1.23029068  1.20237985\n",
      "  -0.38732682 -0.30230275]\n",
      " [-1.04855297 -1.42001794 -1.70627019  1.9507754  -0.50965218 -0.4380743\n",
      "  -1.25279536  0.77749036]\n",
      " [-1.61389785 -0.21274028 -0.89546656  0.3869025  -0.51080514 -1.18063218\n",
      "  -0.02818223  0.42833187]\n",
      " [ 0.06651722  0.3024719  -0.63432209 -0.36274117 -0.67246045 -0.35955316\n",
      "  -0.81314628 -1.7262826 ]\n",
      " [ 0.17742614 -0.40178094 -1.63019835  0.46278226 -0.90729836  0.0519454\n",
      "   0.72909056  0.12898291]\n",
      " [ 1.13940068 -1.23482582  0.40234164 -0.68481009 -0.87079715 -0.57884966\n",
      "  -0.31155253  0.05616534]\n",
      " [-1.16514984  0.90082649  0.46566244 -1.53624369  1.48825219  1.89588918\n",
      "   1.17877957 -0.17992484]\n",
      " [-1.07075262  1.05445173 -0.40317695  1.22244507  0.20827498  0.97663904\n",
      "   0.3563664   0.70657317]]\n",
      "\n",
      "W_k shape: (8, 8)\n",
      "[[ 0.01050002  1.78587049  0.12691209  0.40198936  1.8831507  -1.34775906\n",
      "  -1.270485    0.96939671]\n",
      " [-1.17312341  1.94362119 -0.41361898 -0.74745481  1.92294203  1.48051479\n",
      "   1.86755896  0.90604466]\n",
      " [-0.86122569  1.91006495 -0.26800337  0.8024564   0.94725197 -0.15501009\n",
      "   0.61407937  0.92220667]\n",
      " [ 0.37642553 -1.09940079  0.29823817  1.3263859  -0.69456786 -0.14963454\n",
      "  -0.43515355  1.84926373]\n",
      " [ 0.67229476  0.40746184 -0.76991607  0.53924919 -0.67433266  0.03183056\n",
      "  -0.63584608  0.67643329]\n",
      " [ 0.57659082 -0.20829876  0.39600671 -1.09306151 -1.49125759  0.4393917\n",
      "   0.1666735   0.63503144]\n",
      " [ 2.38314477  0.94447949 -0.91282223  1.11701629 -1.31590741 -0.4615846\n",
      "  -0.06824161  1.71334272]\n",
      " [-0.74475482 -0.82643854 -0.09845252 -0.66347829  1.12663592 -1.07993151\n",
      "  -1.14746865 -0.43782004]]\n",
      "\n",
      "W_v shape: (8, 8)\n",
      "[[-0.49803245  1.92953205  0.94942081  0.08755124 -1.22543552  0.84436298\n",
      "  -1.00021535 -1.5447711 ]\n",
      " [ 1.18802979  0.31694261  0.92085882  0.31872765  0.85683061 -0.65102559\n",
      "  -1.03424284  0.68159452]\n",
      " [-0.80340966 -0.68954978 -0.4555325   0.01747916 -0.35399391 -1.37495129\n",
      "  -0.6436184  -2.22340315]\n",
      " [ 0.62523145 -1.60205766 -1.10438334  0.05216508 -0.739563    1.5430146\n",
      "  -1.29285691  0.26705087]\n",
      " [-0.03928282 -1.1680935   0.52327666 -0.17154633  0.77179055  0.82350415\n",
      "   2.16323595  1.33652795]\n",
      " [-0.36918184 -0.23937918  1.0996596   0.65526373  0.64013153 -1.61695604\n",
      "  -0.02432612 -0.73803091]\n",
      " [ 0.2799246  -0.09815039  0.91017891  0.31721822  0.78632796 -0.4664191\n",
      "  -0.94444626 -0.41004969]\n",
      " [-0.01702041  0.37915174  2.25930895 -0.04225715 -0.955945   -0.34598178\n",
      "  -0.46359597  0.48148147]]\n"
     ]
    }
   ],
   "source": [
    "# CREATING 3 DiFFERENT PRESPECTIVES FOR EACH TOKEN\n",
    "# Query, Key, Value:\n",
    "# These are weight metrices, in my notebook, these are randomm. But in transformer model, learned during training.\n",
    "# Query (Q): what I am  looking for.\n",
    "# Key (K): What can I offer??\n",
    "# Value (V): What is my actual content?\n",
    "\n",
    "# Each word becomes question asker \n",
    "W_q = np.random.randn(embedding_dimension,embedding_dimension)\n",
    "# Each word becomes answer giver\n",
    "W_k = np.random.randn(embedding_dimension, embedding_dimension)\n",
    "# Each word becomes actual content\n",
    "W_v =np.random.randn(embedding_dimension, embedding_dimension)\n",
    "print(\"\\nWeight matrices shapes:\")\n",
    "print(\"W_q shape:\",W_q.shape)\n",
    "print(W_q)\n",
    "print(\"\\nW_k shape:\",W_k.shape)\n",
    "print(W_k)\n",
    "print(\"\\nW_v shape:\",W_v.shape)\n",
    "print(W_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b55abeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In mumpy @ is matrix multiplication.\n",
    "# Spurce: https://numpy.org/doc/2.1/reference/generated/numpy.matmul.html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5062e085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qury shape:shape: (4, 8)\n",
      "[[-5.14329841 -2.44018414 -6.52863207  0.51116581  0.49852547  2.30066161\n",
      "  -0.30223837 -3.7632453 ]\n",
      " [-1.07542068  0.32630062 -2.83567179  0.30794017 -1.45413732  0.1395637\n",
      "  -0.50192854 -1.8374508 ]\n",
      " [-1.59413038 -2.77831285  5.21829436 -3.60000123  5.23621887  2.22688508\n",
      "  -0.94649399  0.02482593]\n",
      " [ 0.78431113 -4.38895788 -0.21823792 -2.46930639  1.27533979  3.27168043\n",
      "   2.0709697  -0.95462633]]\n",
      "\n",
      "Key shape: (4, 8)\n",
      "[[ 2.61868617  5.32088725 -2.21285007  7.40470497  2.23937946 -2.9171613\n",
      "  -3.10951834  9.45599857]\n",
      " [ 1.33168829 -0.28177695 -0.7635857   2.24792734 -1.18126044  0.01953494\n",
      "  -0.52321681  4.300593  ]\n",
      " [ 0.93855483  4.05985713  1.44426359 -0.76083027  2.082033   -1.62971644\n",
      "   0.80743105  0.46588887]\n",
      " [ 3.58543568  1.6722437   0.04461782  0.93055765 -1.35165464 -4.97687382\n",
      "  -6.66446176  2.64844173]]\n",
      "\n",
      "Value shape: (4, 8)\n",
      "[[ 0.76755231 -2.83248751 -0.45197153 -0.23697617 -2.11506695  6.06838635\n",
      "  -2.46877688 -1.27516318]\n",
      " [ 1.37649418 -3.33332497  0.29831589  0.27608958  0.0470815   1.79895109\n",
      "  -1.22484489  1.41340955]\n",
      " [-1.65976969  6.42971514  0.52307405  1.19816234 -1.64862215 -3.65891094\n",
      "  -6.39045808 -7.97834112]\n",
      " [-3.57777262  2.17294989  4.41484294  0.45925557 -2.02144264  1.19483663\n",
      "   2.40483995 -3.56655408]]\n"
     ]
    }
   ],
   "source": [
    "# This is like asking: For each word, what is its query vector, what it wants from others?\n",
    "Q =token_embeddings @ W_q  \n",
    "K= token_embeddings @ W_k \n",
    "V = token_embeddings @ W_v \n",
    "print(\"\\nQury shape:shape:\",Q.shape)\n",
    "print(Q)\n",
    "print(\"\\nKey shape:\",K.shape)\n",
    "print(K)\n",
    "print(\"\\nValue shape:\",V.shape)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df174a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T stands for transpose to swap rows and columns in matrix for computing dot product.\n",
    "#source:https://jtlicardo.com/blog/self-attention-mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25dc07fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-48.46115302, -16.59744429, -29.26081294, -42.41358894],\n",
       "       [-12.00252904,  -4.5856329 ,  -8.5306868 ,  -3.40056023],\n",
       "       [-48.75427426, -18.95702473,   4.01997717, -25.26571042],\n",
       "       [-61.25555622,  -9.73463472, -16.96808943, -41.17160952]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without scaling:\n",
    "attention_scores = (Q @ K.T)\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fc5630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I can see that the attention scores  are too big\n",
    "# I am going to use softmax to convert them to probabilities.\n",
    "# But with this big values, softmax will focus on large values.\n",
    "# I need to scale them.\n",
    "# Source: https://www.youtube.com/watch?v=0PjHri8tc1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09cb62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention scores shape: (4, 4)\n",
      "[[-17.13360496  -5.8680827  -10.34525963 -14.99546818]\n",
      " [ -4.24353484  -1.62126606  -3.01605324  -1.2022796 ]\n",
      " [-17.23723897  -6.70232037   1.42127656  -8.93277758]\n",
      " [-21.6571096   -3.44171311  -5.99912555 -14.55636214]]\n"
     ]
    }
   ],
   "source": [
    "# ATTENSION SCORE: \n",
    "# Now I am going to calculate attention scores that I can see how each word attends to other words.\n",
    "scale= np.sqrt(embedding_dimension)\n",
    "attention_scores = (Q @ K.T)/ scale\n",
    "# If I can explain clearly: \n",
    "# Word1 asks Q1, Word2 answers with K2 calculate match score\n",
    "# Higher score = We understand each other well\n",
    "# For example, scores: Word1 with Word2 = 0.9 which is high, Word1 with Word3 = 0.5, Word1 with Word4 = 0.1\n",
    "print(\"\\nAttention scores shape:\",attention_scores.shape)\n",
    "print(attention_scores)\n",
    "# Now it looks better.\n",
    "# 48/2.8 = 17.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222787d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention weights shape: (4, 4)\n",
      "[[1.26615123e-05 9.88643541e-01 1.12363822e-02 1.07415409e-04]\n",
      " [2.55682235e-02 3.51995745e-01 8.72547416e-02 5.35181290e-01]\n",
      " [7.88074176e-09 2.96363089e-04 9.99671776e-01 3.18528907e-05]\n",
      " [1.13953720e-08 9.28057076e-01 7.19290918e-02 1.38211425e-05]]\n"
     ]
    }
   ],
   "source": [
    "# ATTENTION WEIGHT:\n",
    "# Here, raw score is turned into probabilities like saying pay X%  attention here\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    x_shifted= x - np.max(x, axis=axis,keepdims=True)\n",
    "    exp_x= np.exp(x_shifted)\n",
    "    return exp_x / np.sum(exp_x, axis=axis,keepdims=True)\n",
    "attention_weights= softmax(attention_scores)\n",
    "\n",
    "# Softmax makes things differentiable and focuses on high scores while ignoring lows.\n",
    "# Source: https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python\n",
    "print(\"\\nAttention weights shape:\",attention_weights.shape)\n",
    "print(attention_weights)\n",
    "# here, the softmax made values in probability form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention output shape: (4, 8)\n",
      "[[ 1.34183768 -3.22302592  0.30127404  0.28646352  0.02777836  1.73761364\n",
      "  -1.28251356  1.30731129]\n",
      " [-1.5554347   0.47820738  2.50183185  0.44145363 -1.2631944   1.10857787\n",
      "   0.23516515 -2.13999061]\n",
      " [-1.65893093  6.42668607  0.5231314   1.19786552 -1.64813149 -3.65713874\n",
      "  -6.388647   -7.97541717]\n",
      " [ 1.15802999 -2.63100225  0.31453943  0.34241596 -0.07491754  1.40636373\n",
      "  -1.5963526   0.7378006 ]]\n"
     ]
    }
   ],
   "source": [
    "# CREATING NEW UNDERSTANDING:\n",
    "# Here, each word creates a new version of itself by mixing other words information.\n",
    "# The model learns contextual meaning\n",
    "# Each word becomes smarter by considering its neighbors \n",
    "# For example: word bank can learn from account,bank account.\n",
    "Attention_output= attention_weights @V\n",
    "print(\"\\nAttention output shape:\",Attention_output.shape)\n",
    "print(Attention_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a4e5a",
   "metadata": {},
   "source": [
    "<h2><center>Multi Head Self attention and masking from scratch<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f21ce646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In here  I am going to create multi head attention from scratch,  multiple heads self attention mechanism is like having many brains.\n",
    "# from what I understand, it helps the model focus on different parts of the input parallelly.\n",
    "# In single head attention, I have one set of Q, K, V  per token. but here, I will have multiple sets of Q, K, V per token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f12d7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For multi head attention, I am going to define some hyperparameters\n",
    "# The frist one is going to be:\n",
    "# Number of head attention, what I understand, it is like number of specialists for monitoring attention pattern\n",
    "# While I was reading some articles, some LLMs use 128 heads.\n",
    "# Second one is going to be: \n",
    "# I have to give equal capacity to each head to learn the patterns, So I divide the embedding dimension by number of heads.\n",
    "num_heads = 2\n",
    "# I have already  embedding_dimension which is 8, so each head can get 4 dimension to learn patterns.\n",
    "head_dimension = embedding_dimension // num_heads \n",
    "head_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20234a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embeddings: (4, 8)\n",
      "[[-1.54079701  0.06326199  0.15650654  0.23218104 -0.59731607 -0.23792173\n",
      "  -1.42406091 -0.49331988]\n",
      " [-0.54286148  0.41605005 -1.15618243  0.7811981   1.49448454 -2.06998503\n",
      "   0.42625873  0.67690804]\n",
      " [-0.63743703 -0.39727181 -0.13288058 -0.29779088 -0.30901297 -1.67600381\n",
      "   1.15233156  1.07961859]\n",
      " [-0.81336426 -1.46642433  0.52106488 -0.57578797  0.14195316 -0.31932842\n",
      "   0.69153875  0.69474914]]\n"
     ]
    }
   ],
   "source": [
    "# INPUT EMBEDDINGS:\n",
    "# I need reproducible numbers\n",
    "# transformer models use pretrained embeddings like word2vec, GloVe, FastText,BERT.\n",
    "# real models get semantic meaning, similar words have similar vectors.\n",
    "# In here, each word  has 8 traits.\n",
    "token_embeddings_multi_heads = np.random.randn(sequence_length, embedding_dimension)\n",
    "print(\"token_embeddings:\", token_embeddings_multi_heads.shape)\n",
    "print(token_embeddings_multi_heads)\n",
    "# In output, I can see that 4 tokens, each has 8 demensions you know that is like 8 personality \n",
    "# What I learned, token embeddings give passport to each word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd09660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Projection Matrix\n",
      "(8, 8)\n",
      "[[-0.72559738 -1.38336396 -1.5829384   0.61037938 -1.18885926 -0.50681635\n",
      "  -0.59631404 -0.0525673 ]\n",
      " [-1.93627981  0.1887786   0.52389102  0.08842209 -0.31088617  0.09740017\n",
      "   0.39904635 -2.77259276]\n",
      " [ 1.95591231  0.39009332 -0.65240858 -0.39095338  0.49374178 -0.11610394\n",
      "  -2.03068447  2.06449286]\n",
      " [-0.11054066  1.02017271 -0.69204985  1.53637705  0.28634369  0.60884383\n",
      "  -1.04525337  1.21114529]\n",
      " [ 0.68981816  1.30184623 -0.62808756 -0.48102712  2.3039167  -1.06001582\n",
      "  -0.1359497   1.13689136]\n",
      " [ 0.09772497  0.58295368 -0.39944903  0.37005589 -1.30652685  1.65813068\n",
      "  -0.11816405 -0.6801782 ]\n",
      " [ 0.66638308 -0.46071979 -1.33425847 -1.34671751  0.69377315 -0.15957344\n",
      "  -0.13370156  1.07774381]\n",
      " [-1.12682581 -0.73067775 -0.38487981  0.09435159 -0.04217145 -0.28688719\n",
      "  -0.0616264  -0.10730528]]\n",
      "\n",
      "Key Projection Matrix\n",
      "(8, 8)\n",
      "[[-0.71960439 -0.81299299  0.27451636 -0.89091508 -1.15735526 -0.31229225\n",
      "  -0.15766702  2.2567235 ]\n",
      " [-0.70470028  0.94326072  0.74718833 -1.18894496  0.77325298 -1.18388064\n",
      "  -2.65917224  0.60631952]\n",
      " [-1.75589058  0.45093446 -0.6840109   1.6595508   1.0685094  -0.4533858\n",
      "  -0.68783761 -1.2140774 ]\n",
      " [-0.44092263 -0.2803555  -0.36469354  0.15670386  0.5785215   0.34965446\n",
      "  -0.76414392 -1.43779147]\n",
      " [ 1.36453185 -0.68944918 -0.6522936  -0.52118931 -1.84306955 -0.477974\n",
      "  -0.47965581  0.6203583 ]\n",
      " [ 0.69845715  0.00377089  0.93184837  0.33996498 -0.01568211  0.16092817\n",
      "  -0.19065349 -0.39484951]\n",
      " [-0.26773354 -1.12801133  0.28044171 -0.99312361  0.84163126 -0.24945858\n",
      "   0.04949498  0.49383678]\n",
      " [ 0.64331447 -1.57062341 -0.20690368  0.88017891 -1.69810582  0.38728048\n",
      "  -2.25556423 -1.02250684]]\n",
      "\n",
      "Value Projection Matrix\n",
      "(8, 8)\n",
      "[[ 0.03863055 -1.6567151  -0.98551074 -1.47183501  1.64813493  0.16422776\n",
      "   0.56729028 -0.2226751 ]\n",
      " [-0.35343175 -1.61647419 -0.29183736 -0.76149221  0.85792392  1.14110187\n",
      "   1.46657872  0.85255194]\n",
      " [-0.59865394 -1.11589699  0.76666318  0.35629282 -1.76853845  0.35548179\n",
      "   0.81451982  0.05892559]\n",
      " [-0.18505367 -0.80764849 -1.4465347   0.80029795 -0.30911444 -0.23346666\n",
      "   1.73272119  0.68450111]\n",
      " [ 0.370825    0.14206181  1.51999486  1.71958931  0.92950511  0.58222459\n",
      "  -2.09460307  0.12372191]\n",
      " [-0.13010695  0.09395323  0.94304609 -2.73967717 -0.56931205  0.26990435\n",
      "  -0.46684555 -1.41690611]\n",
      " [ 0.86896349  0.27687191 -0.97110457  0.3148172   0.82158571  0.00529265\n",
      "   0.8005648   0.07826018]\n",
      " [-0.39522898 -1.15942052 -0.08593077  0.19429294  0.87583276 -0.11510747\n",
      "   0.45741561 -0.96461201]]\n",
      "\n",
      "Output Projection Matrix\n",
      "(8, 8)\n",
      "[[-0.78262916 -0.1103893  -1.05462846  0.82024784  0.46313033  0.27909576\n",
      "   0.33890413  2.02104356]\n",
      " [-0.46886419 -2.20144129  0.1993002  -0.05060354 -0.51751904 -0.97882986\n",
      "  -0.43918952  0.18133843]\n",
      " [-0.5028167   2.41245368 -0.96050438 -0.79311736 -2.28862004  0.25148442\n",
      "  -2.01640663 -0.53945463]\n",
      " [-0.27567053 -0.70972797  1.73887268  0.99439439  1.31913688 -0.88241882\n",
      "   1.12859406  0.49600095]\n",
      " [ 0.77140595  1.02943883 -0.90876325 -0.42431762  0.86259601 -2.65561909\n",
      "   1.51332808  0.55313206]\n",
      " [-0.04570396  0.22050766 -1.02993528 -0.34994336  1.10028434  1.29802197\n",
      "   2.69622405 -0.07392467]\n",
      " [-0.65855297 -0.51423397 -1.01804188 -0.07785476  0.38273243 -0.03424228\n",
      "   1.09634685 -0.2342158 ]\n",
      " [-0.34745065 -0.58126848 -1.63263453 -1.56776772 -1.17915793  1.30142807\n",
      "   0.89526027  1.37496407]]\n"
     ]
    }
   ],
   "source": [
    "# PROJECTION MATRICES:\n",
    "# My raw word embeddings are not ready for attention, the next step is to transform  them into Query projections, Key projections, Value projections.\n",
    "# Search query, from what I understand, this creates search query from learning and extracting of word that are relavant to ask questions.\n",
    "# Key projection matrix learns to extract  that aspect of the word embeddings that  make useful \n",
    "# Value projection matrix makes the actual content \n",
    "# Output projection matrix,   \n",
    "# Overall, I can say that projection matrices helps the model to learn different  roles for the same word.\n",
    "\n",
    "W_Q = np.random.randn(embedding_dimension, embedding_dimension)\n",
    "W_K =np.random.randn(embedding_dimension, embedding_dimension)\n",
    "W_V= np.random.randn(embedding_dimension, embedding_dimension)\n",
    "W_OutPut =np.random.randn(embedding_dimension, embedding_dimension)\n",
    "# PROJECTING QUERY, KEY, VALUE:\n",
    "# Now, I can create 3 different roles, Google News dataset model has 300 dimension vectors.\n",
    "Q_Multi_Head = token_embeddings_multi_heads @ W_Q\n",
    "K_Multi_Head = token_embeddings_multi_heads @ W_K\n",
    "V_Multi_Head = token_embeddings_multi_heads @ W_V\n",
    "\n",
    "print(\"Query Projection Matrix\")\n",
    "print(W_Q.shape)\n",
    "print(W_Q)\n",
    "print(\"\\nKey Projection Matrix\")\n",
    "print(W_K.shape)\n",
    "print(W_K)\n",
    "print(\"\\nValue Projection Matrix\")\n",
    "print(W_V.shape)\n",
    "print(W_V)\n",
    "print(\"\\nOutput Projection Matrix\")\n",
    "print(W_OutPut.shape)\n",
    "print(W_OutPut)\n",
    "\n",
    "# What I can see here, from 8 demensions of each word, Query, Key, Value projections are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a11c0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q_Multi_Head shape: (4, 8)\n",
      "[[ 4.47578083e-01  2.54158236e+00  4.76948068e+00  1.43119702e+00\n",
      "  -7.66056412e-02  1.51768244e+00  7.13659381e-01 -1.48918392e+00]\n",
      " [-2.40950851e+00  1.22335049e+00  3.49875274e-01 -6.37415661e-01\n",
      "   6.58371685e+00 -4.35317936e+00  1.96374714e+00  9.28000610e-01]\n",
      " [ 1.79169258e-01 -2.24789816e+00  4.20871333e-03 -2.75134780e+00\n",
      "   2.96218145e+00 -2.82659596e+00  8.22140298e-01  2.41471879e+00]\n",
      " [ 4.25707194e+00 -3.63385788e-01 -5.73904191e-01 -2.76667391e+00\n",
      "   2.70999678e+00 -1.13129300e+00 -6.73264833e-01  5.53626257e+00]]\n",
      "\n",
      "K_Multi_Head shape: (4, 8)\n",
      "[[-0.23032457  4.10990919 -0.69681036  2.80410693  2.87751884  0.82791391\n",
      "   1.16373507 -4.4380722 ]\n",
      " [ 2.69795373 -2.48875856 -2.25648205 -3.11750308 -3.3461424  -0.41730036\n",
      "  -2.65033961  0.57047362]\n",
      " [-0.1029719  -2.62172077 -1.53275905  0.17017102 -0.15136576  0.63415146\n",
      "  -0.43448628 -1.15468744]\n",
      " [ 1.19009161 -2.29589606 -1.80537549  2.98481686 -0.82326731  1.52982212\n",
      "   2.56926124 -2.68413999]]\n",
      "\n",
      "V_Multi_Head shape: (4, 8)\n",
      "[[-1.45156692  2.15870789  1.57715457  1.54172459 -4.85553619 -0.54216503\n",
      "  -0.25501028  1.19280838]\n",
      " [ 1.30595453  0.23710507 -1.75544728  9.20213778  4.77616856  0.02798359\n",
      "  -0.79903749  3.44046863]\n",
      " [ 0.92854822  0.95297395 -2.18902387  5.58792573  1.49488917 -1.2861738\n",
      "   1.27758027  0.97685521]\n",
      " [ 0.7019979   2.97765491  1.64528505  3.5103095  -1.85176733 -1.56711041\n",
      "  -2.46215049 -1.57853271]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQ_Multi_Head shape:\",Q_Multi_Head.shape)\n",
    "print(Q_Multi_Head)\n",
    "print(\"\\nK_Multi_Head shape:\",K_Multi_Head.shape)\n",
    "print(K_Multi_Head)\n",
    "print(\"\\nV_Multi_Head shape:\",V_Multi_Head.shape)\n",
    "print(V_Multi_Head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d20a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI HEAD SPLITTING:\n",
    "# iam going to create a function to split 8 dimension into 2 heads.\n",
    "def split_heads(Input, num_heads):\n",
    "    return Input.reshape(sequence_length, num_heads, head_dimension).transpose(1, 0, 2)\n",
    "\n",
    "# COMBINING HEADS BACK:\n",
    "def mergee_heads(heads):\n",
    "    return heads.transpose(1, 0, 2).reshape(sequence_length, embedding_dimension)\n",
    "\n",
    "# I defined the softmax function already above, when I printed projections, all 8 demensions are printed together or worked together.\n",
    "# here each head  have half of that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d4c22f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_heads shape: (2, 4, 4)\n",
      "[[[ 4.47578083e-01  2.54158236e+00  4.76948068e+00  1.43119702e+00]\n",
      "  [-2.40950851e+00  1.22335049e+00  3.49875274e-01 -6.37415661e-01]\n",
      "  [ 1.79169258e-01 -2.24789816e+00  4.20871333e-03 -2.75134780e+00]\n",
      "  [ 4.25707194e+00 -3.63385788e-01 -5.73904191e-01 -2.76667391e+00]]\n",
      "\n",
      " [[-7.66056412e-02  1.51768244e+00  7.13659381e-01 -1.48918392e+00]\n",
      "  [ 6.58371685e+00 -4.35317936e+00  1.96374714e+00  9.28000610e-01]\n",
      "  [ 2.96218145e+00 -2.82659596e+00  8.22140298e-01  2.41471879e+00]\n",
      "  [ 2.70999678e+00 -1.13129300e+00 -6.73264833e-01  5.53626257e+00]]]\n",
      "K_heads shape: (2, 4, 4)\n",
      "[[[-0.23032457  4.10990919 -0.69681036  2.80410693]\n",
      "  [ 2.69795373 -2.48875856 -2.25648205 -3.11750308]\n",
      "  [-0.1029719  -2.62172077 -1.53275905  0.17017102]\n",
      "  [ 1.19009161 -2.29589606 -1.80537549  2.98481686]]\n",
      "\n",
      " [[ 2.87751884  0.82791391  1.16373507 -4.4380722 ]\n",
      "  [-3.3461424  -0.41730036 -2.65033961  0.57047362]\n",
      "  [-0.15136576  0.63415146 -0.43448628 -1.15468744]\n",
      "  [-0.82326731  1.52982212  2.56926124 -2.68413999]]]\n",
      "V_heads shape: (2, 4, 4)\n",
      "[[[-1.45156692  2.15870789  1.57715457  1.54172459]\n",
      "  [ 1.30595453  0.23710507 -1.75544728  9.20213778]\n",
      "  [ 0.92854822  0.95297395 -2.18902387  5.58792573]\n",
      "  [ 0.7019979   2.97765491  1.64528505  3.5103095 ]]\n",
      "\n",
      " [[-4.85553619 -0.54216503 -0.25501028  1.19280838]\n",
      "  [ 4.77616856  0.02798359 -0.79903749  3.44046863]\n",
      "  [ 1.49488917 -1.2861738   1.27758027  0.97685521]\n",
      "  [-1.85176733 -1.56711041 -2.46215049 -1.57853271]]]\n"
     ]
    }
   ],
   "source": [
    "# Now I can split the projections into two heads.\n",
    "Q_heads = split_heads(Q_Multi_Head, num_heads)\n",
    "K_heads= split_heads(K_Multi_Head, num_heads)\n",
    "V_heads =split_heads(V_Multi_Head,num_heads)\n",
    "\n",
    "print(\"Q_heads shape:\",Q_heads.shape)\n",
    "print(Q_heads)\n",
    "print(\"K_heads shape:\",K_heads.shape)\n",
    "print(K_heads)\n",
    "print(\"V_heads shape:\",V_heads.shape)\n",
    "print(V_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_probability: (2, 4, 4)\n",
      "[[[9.99963332e-01 1.53870247e-07 4.10053267e-06 3.24137406e-05]\n",
      "  [9.67739343e-01 2.52258338e-03 2.70362840e-02 2.70178972e-03]\n",
      "  [1.33154827e-07 9.90113425e-01 9.72887147e-03 1.57570489e-04]\n",
      "  [1.04818042e-07 9.99969812e-01 2.26947317e-05 7.38823758e-06]]\n",
      "\n",
      " [[5.18500317e-01 1.57476567e-03 2.46516988e-02 4.55273218e-01]\n",
      "  [9.99921946e-01 4.59571476e-09 6.80848552e-05 9.96497395e-06]\n",
      "  [6.76457873e-01 3.44044068e-02 2.73665270e-01 1.54724505e-02]\n",
      "  [5.13095363e-04 8.55991247e-01 1.43312410e-01 1.83247828e-04]]]\n",
      "\n",
      "Output (2, 4, 4)\n",
      "[[[-1.45148693  2.15872919  1.57714082  1.54180617]\n",
      "  [-1.3744429   2.12347454  1.4671084   1.67576157]\n",
      "  [ 1.30218726  0.24450175 -1.75912919  9.16607769]\n",
      "  [ 1.30594122  0.23714176 -1.75543164  9.2020129 ]]\n",
      "\n",
      " [[-3.31628422 -1.02623844 -1.22293786 -0.07069307]\n",
      "  [-4.85507384 -0.54222589 -0.25492793  1.19276607]\n",
      "  [-2.73979657 -0.74201718  0.11153973  1.16815948]\n",
      "  [ 4.29976396 -0.16093631 -0.50145802  3.08532927]]]\n",
      "\n",
      "Combined output shape: (4, 8)\n",
      "[[-1.45148693  2.15872919  1.57714082  1.54180617 -3.31628422 -1.02623844\n",
      "  -1.22293786 -0.07069307]\n",
      " [-1.3744429   2.12347454  1.4671084   1.67576157 -4.85507384 -0.54222589\n",
      "  -0.25492793  1.19276607]\n",
      " [ 1.30218726  0.24450175 -1.75912919  9.16607769 -2.73979657 -0.74201718\n",
      "   0.11153973  1.16815948]\n",
      " [ 1.30594122  0.23714176 -1.75543164  9.2020129   4.29976396 -0.16093631\n",
      "  -0.50145802  3.08532927]]\n",
      "\n",
      "Final output shape: (4, 8)\n",
      "[[ -2.7755846   -4.85180807   8.55826284   0.95481229  -7.73950109\n",
      "    3.94255699 -12.06973762  -4.19736423]\n",
      " [ -5.08658156  -7.85277573   6.66025394  -0.33235144  -9.17117826\n",
      "   10.17854411 -10.48638012  -3.29869505]\n",
      " [ -5.33498067 -15.15168838  17.53702534  11.14775711  12.07931541\n",
      "   -0.57744606   9.24707202   8.29090533]\n",
      " [ -0.20486249  -8.57672063   8.08878493   5.03570281  16.34019503\n",
      "  -16.02406079  22.54887384  14.94345059]]\n",
      "\n",
      "Row sums per head:\n",
      " [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "multi_head_scale = np.sqrt(head_dimension)\n",
    "\n",
    "attention_weight_multi_head= np.zeros((num_heads, sequence_length, sequence_length))\n",
    "head_outputs= np.zeros((num_heads,sequence_length,head_dimension))\n",
    "\n",
    "# To process each head separately, I am going to use for loop.\n",
    "for head in range(num_heads):\n",
    "    scores_multi_head = (Q_heads[head] @K_heads[head].T) /multi_head_scale             \n",
    "    weights= softmax(scores_multi_head)        \n",
    "    out= weights @V_heads[head]                              \n",
    "\n",
    "    attention_weight_multi_head[head] = weights\n",
    "    head_outputs[head]= out\n",
    "\n",
    "Combined_output= mergee_heads(head_outputs)\n",
    "# What i noticed here form reeading \n",
    "# To mix information across both heads, I am going to use output projection matrix.\n",
    "# Because in real models,  heads can collaborate. not stay isolated\n",
    "Output_projection = Combined_output @ W_OutPut\n",
    "print(\"attention_probability:\", attention_weight_multi_head.shape)\n",
    "print(attention_weight_multi_head)\n",
    "\n",
    "print(\"\\nOutput\", head_outputs.shape)\n",
    "print(head_outputs)\n",
    "print(\"\\nCombined output shape:\",Combined_output.shape)\n",
    "print(Combined_output)\n",
    "print(\"\\nFinal output shape:\",Output_projection.shape)\n",
    "print(Output_projection)\n",
    "print(\"\\nRow sums per head:\\n\", np.round(attention_weight_multi_head.sum(axis=-1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0548ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources:\n",
    "# https://www.geeksforgeeks.org/nlp/multi-head-attention-mechanism\n",
    "# https://www.datacamp.com/de/tutorial/multi-head-attention-transformers\n",
    "# https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention\n",
    "# https://www.kaggle.com/discussions/general/506393\n",
    "# https://datajourney24.substack.com/p/inside-the-transformer-attention\n",
    "# https://sungwookyoo.github.io/tips/study/Multihead_Attention\n",
    "# https://blog.dailydoseofds.com/p/implement-attention-is-all-you-need\n",
    "# https://agrimpaneru.com.np/blog/multi-head-attention-pytorch/\n",
    "# https://medium.com/%40wangdk93/multihead-attention-from-scratch-6fd6f99b9651\n",
    "# https://www.digitalocean.com/community/tutorials/multi-head-attention-simple-explained?\n",
    "# For debugging, I used QWEN3 MAX model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d7c02",
   "metadata": {},
   "source": [
    "<h2><center>Masked Multi Head Attention<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358675c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal mask: [[0 1 1 1]\n",
      " [0 0 1 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n",
      "attention_probability with causal mask: (2, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# what I learned:\n",
    "# Biredictional attention like BERT model, can see context from both  directions.\n",
    "# and casual attention can see only previous words.\n",
    "\n",
    "# triu is  triangular upper, \n",
    "# https://www.mindspore.cn/docs/api/en/r1.6/api_python/nn/mindspore.nn.Triu.html?\n",
    "\n",
    "# To force the model to predict next word.\n",
    "def causal_mask(sequence_length):\n",
    " # Here I the attenion for next is masked\n",
    "    return np.triu(np.ones((sequence_length, sequence_length), dtype=bool), k=1)\n",
    "\n",
    "causal_mask= causal_mask(sequence_length)\n",
    "\n",
    "# Again, I am going to use for loop to get causal mask in attention calculation.\n",
    "for head in range(num_heads):\n",
    "    # Copying above scores\n",
    "    scores_multi_head =scores_multi_head.copy()  \n",
    "    scores_multi_head[causal_mask]= -np.inf \n",
    "    weights =softmax(scores_multi_head)\n",
    "    out =weights @V_heads[head]\n",
    "\n",
    "    attention_weight_multi_head[head]= weights\n",
    "    head_outputs[head]= out\n",
    "\n",
    "print(\"Causal mask:\", causal_mask.astype(int))\n",
    "print(\"attention_probability with causal mask:\", attention_weight_multi_head.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c8524",
   "metadata": {},
   "source": [
    "<h2><center>Encoder block<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5df7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23793323, -0.30976864,  1.74463472,  0.59935388, -0.84960496,\n",
       "         0.9823896 , -1.63419152, -0.29487986],\n",
       "       [-0.52110109, -0.81457811,  1.28682346,  0.46592678, -0.85354551,\n",
       "         1.70975523, -1.24058029, -0.03270049],\n",
       "       [-1.00132315, -1.91677372,  1.23331294,  0.60677925,  0.69475696,\n",
       "        -0.6458158 ,  0.56370861,  0.4653549 ],\n",
       "       [-0.48051199, -1.18605476,  0.272184  , -0.05224626,  0.88761819,\n",
       "        -1.67859017,  1.41596033,  0.82164067]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LAYER NORMALIZATION:\n",
    "# To normalize each token separately, before processing, I can use layer normalization.  \n",
    "# Calcaulating  average of all 8 demensions for tken. \n",
    "def layer_normalization(x,epsilon = 0.00001):\n",
    "    mean = x.mean(axis=-1, keepdims=True)\n",
    "    variance= x.var(axis=-1, keepdims=True)\n",
    "    normalized_x = (x -mean)/ np.sqrt(variance+ epsilon)\n",
    "    return normalized_x\n",
    "\n",
    "x1 = layer_normalization(token_embeddings_multi_heads + Output_projection)\n",
    "x1\n",
    "#  in real models,  layer normalization apply gamma and beta afterward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3c097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: (4, 8)\n",
      "Feed forward  Network Output shape: (4, 8)\n",
      "x2 shape: (4, 8)\n",
      "\n",
      " token mean : [0. 0. 0. 0.]\n",
      " token std : [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# FEED FORWARD NETWORK: \n",
    "# Like other neural networks, The transformer model should learn nonlinear patterns.\n",
    "# Here I have two linear layers with one relu activation in the middle.\n",
    "latent_dimension= 16 \n",
    "Weights_matrix1 = np.random.randn(embedding_dimension, latent_dimension)\n",
    "Bias1= np.zeros((latent_dimension,))\n",
    "\n",
    "Weights_matrix2 =np.random.randn(latent_dimension, embedding_dimension)\n",
    "Bias2 =np.zeros((embedding_dimension,))\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "Hidden = relu(x1 @Weights_matrix1 + Bias1)\n",
    "OutPut= Hidden@ Weights_matrix2 +Bias2\n",
    "\n",
    "x2= layer_normalization(x1 + OutPut )\n",
    "\n",
    "\n",
    "print(\"x1 shape:\", x1.shape)\n",
    "print(\"Feed forward  Network Output shape:\",OutPut.shape)\n",
    "print(\"x2 shape:\", x2.shape)\n",
    "\n",
    "print(\"\\n token mean :\",np.round(x2.mean(axis=-1), 4))\n",
    "print(\" token std :\", np.round(x2.std(axis=-1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c60c7a",
   "metadata": {},
   "source": [
    "<h2><center>Output Layer<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e8b6705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: (4, 20)\n",
      "Probabilities shape: (4, 20)\n",
      "Row sums: [1. 1. 1. 1.]\n",
      "Predicted_token_id per position: [7 7 1 1]\n",
      "\n",
      "Next token prediction:\n",
      "Top id: 1\n",
      "Top probability: 0.5143953992508514\n"
     ]
    }
   ],
   "source": [
    "# OUTPUT LAYER: \n",
    "# In this cell, I am going to converts each row into scores for every vocabulary token\n",
    "# In real library, that is called logits\n",
    "\n",
    "vocablry_size = 20 \n",
    "# Here unembedding \n",
    "Weight_vocab =np.random.randn(embedding_dimension, vocablry_size)\n",
    "b_vocab= np.zeros((vocablry_size,))\n",
    "\n",
    "Logits= x2 @Weight_vocab+ b_vocab\n",
    "# Applying softmax to get probability        \n",
    "Probabilities= softmax(Logits, axis=-1) \n",
    "\n",
    "Predicted_token_id= np.argmax(Probabilities,axis=-1)\n",
    "\n",
    "print(\"Logits shape:\", Logits.shape)\n",
    "print(\"Probabilities shape:\", Probabilities.shape)\n",
    "print(\"Row sums:\", np.round(Probabilities.sum(axis=-1), 4))\n",
    "print(\"Predicted_token_id per position:\", Predicted_token_id)\n",
    "\n",
    "print(\"\\nNext token prediction:\")\n",
    "print(\"Top id:\", int(Predicted_token_id[-1]))\n",
    "print(\"Top probability:\", float(np.max(Probabilities[-1])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
