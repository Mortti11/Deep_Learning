{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff13fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import torch.nn.functional as F\n",
    "from tensorboard import summary\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import  precision_score, recall_score, f1_score,  roc_auc_score, average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5de074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I trained the CNN model in Keras framework already, I am going to build CNN in PyTorch framework to see, could I get better result.\n",
    "# I will use the same code structure for prepring data in here as in Keras notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b6a75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccebe953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Humidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CO2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupancy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weekend",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tod_sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tod_cos",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "aa5e1d82-6813-435b-8e82-f5bdf329e0ff",
       "rows": [
        [
         "0",
         "23.18",
         "27.272",
         "721.25",
         "1",
         "0",
         "-0.9992290362407228",
         "-0.039259815759069"
        ],
        [
         "1",
         "23.15",
         "27.2675",
         "714.0",
         "1",
         "0",
         "-0.9992290362407228",
         "-0.039259815759069"
        ],
        [
         "2",
         "23.15",
         "27.245",
         "713.5",
         "1",
         "0",
         "-0.9995335908367128",
         "-0.0305385132098227"
        ],
        [
         "3",
         "23.15",
         "27.2",
         "708.25",
         "1",
         "0",
         "-0.9996573249755571",
         "-0.0261769483078734"
        ],
        [
         "4",
         "23.1",
         "27.2",
         "704.5",
         "1",
         "0",
         "-0.9997620270799092",
         "-0.0218148850345608"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>CO2</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>weekend</th>\n",
       "      <th>tod_sin</th>\n",
       "      <th>tod_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>721.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999229</td>\n",
       "      <td>-0.039260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>714.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999229</td>\n",
       "      <td>-0.039260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>713.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999534</td>\n",
       "      <td>-0.030539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>708.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999657</td>\n",
       "      <td>-0.026177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>704.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999762</td>\n",
       "      <td>-0.021815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity     CO2  Occupancy  weekend   tod_sin   tod_cos\n",
       "0        23.18   27.2720  721.25          1        0 -0.999229 -0.039260\n",
       "1        23.15   27.2675  714.00          1        0 -0.999229 -0.039260\n",
       "2        23.15   27.2450  713.50          1        0 -0.999534 -0.030539\n",
       "3        23.15   27.2000  708.25          1        0 -0.999657 -0.026177\n",
       "4        23.10   27.2000  704.50          1        0 -0.999762 -0.021815"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the DSs \n",
    "df_test = pd.read_csv('cleaned_datatest.csv')\n",
    "df_val = pd.read_csv('datavalidation.csv')\n",
    "df_train = pd.read_csv('datatraining.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3162e4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(df_train.duplicated().sum())\n",
    "print(df_val.duplicated().sum())\n",
    "print(df_test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a3c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a3d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8117, 6) (8117,)\n",
      "Val: (2663, 6) (2663,)\n",
      "Test: (9720, 6) (9720,)\n"
     ]
    }
   ],
   "source": [
    "# Preparing data for CNN model,\n",
    "target = 'Occupancy'\n",
    "features = [\"Temperature\", \"Humidity\", \"CO2\", \"weekend\", \"tod_sin\", \"tod_cos\"]\n",
    "\n",
    "X_train = df_train[features].values\n",
    "y_train = df_train[target].values.astype(int)\n",
    "\n",
    "X_val = df_val[features].values\n",
    "y_val = df_val[target].values.astype(int)\n",
    "\n",
    "X_test = df_test[features].values\n",
    "y_test = df_test[target].values.astype(int)\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Scaling the features, I will fit only the train  DS\n",
    "# Because the weekend is binary and tod_sin, tod_cos are already normialized, to -1 , 1. So I will Standardize the continuous features.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled[:, 0:3] = scaler.fit_transform(X_train_scaled[:, 0:3])\n",
    "\n",
    "# transforming val and test DS \n",
    "X_val_scaled[:, 0:3] = scaler.transform(X_val_scaled[:, 0:3])\n",
    "X_test_scaled[:, 0:3]= scaler.transform(X_test_scaled[:, 0:3])\n",
    "\n",
    "print(\"Train:\", X_train_scaled.shape, y_train.shape)\n",
    "print(\"Val:\", X_val_scaled.shape, y_val.shape)\n",
    "print(\"Test:\", X_test_scaled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153e0047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekend unique: [0. 1.]\n",
      "tod_sin min/max: -1.0 1.0\n",
      "tod_cos min/max: -1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Checking the weekend and tod_sin, tod_cos. \n",
    "print(\"weekend unique:\", np.unique(X_train_scaled[:,3]))\n",
    "print(\"tod_sin min/max:\", X_train_scaled[:,4].min(), X_train_scaled[:,4].max())\n",
    "print(\"tod_cos min/max:\", X_train_scaled[:,5].min(), X_train_scaled[:,5].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2edb1e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: (8057, 60, 6) (8057,)\n",
      "Val windows: (2603, 60, 6) (2603,)\n",
      "Test windows: (9660, 60, 6) (9660,)\n"
     ]
    }
   ],
   "source": [
    "# MAKING SEQUENCES:\n",
    "# The CNN model for time series, needs sequences as input \n",
    "# I will create windows of minutes that the model will predict right after the window, the next minute\n",
    "\n",
    "# Creating function\n",
    "window_size = 60\n",
    "step_ahead = 1\n",
    "def windows_time(X, y, window_size = None, step_ahead = None):\n",
    "   # I will creaate two lists for storing  features and the target\n",
    "   # The end should start the a window\n",
    "   X_windows = []\n",
    "   y_windows = []\n",
    "   last_start = len(X) - window_size - step_ahead + 1\n",
    "   for start in range(last_start):\n",
    "        end = start + window_size\n",
    "        X_windows.append(X[start:end])                  \n",
    "        y_windows.append(y[end + step_ahead - 1])      \n",
    "   return np.array(X_windows), np.array(y_windows)\n",
    "\n",
    "X_train_window, y_train_window = windows_time(X_train_scaled, y_train, window_size, step_ahead)\n",
    "X_val_window, y_val_window = windows_time(X_val_scaled, y_val, window_size, step_ahead)\n",
    "X_test_window, y_test_window = windows_time(X_test_scaled, y_test, window_size, step_ahead)\n",
    "\n",
    "print(\"Train windows:\", X_train_window.shape, y_train_window.shape)\n",
    "print(\"Val windows:\", X_val_window.shape,y_val_window.shape)\n",
    "print(\"Test windows:\", X_test_window.shape, y_test_window.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b86ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_window, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_window, dtype=torch.long) \n",
    "X_val_tensor = torch.tensor(X_val_window, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_window, dtype=torch.long)\n",
    "X_test_tensor= torch.tensor(X_test_window, dtype=torch.float32)\n",
    "y_test_tensor= torch.tensor(y_test_window, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba580d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "504a9af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([128, 60, 6])\n",
      "Batch target shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# I nned to see shape of one batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    print(f\"Batch input shape: {X_batch.shape}\") \n",
    "    print(f\"Batch target shape: {y_batch.shape}\")\n",
    "    break  \n",
    "# In forward function, I will switch input shape and sequence lemght"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b82d6",
   "metadata": {},
   "source": [
    "<h2><center>CNN Architecture<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "680f1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to build 1D CNN for time series classification. Same issue here, the imbalanced rate is not same for each DS.\n",
    "# First I need to create a convolutional block class \n",
    "# Second, I am going to create the CNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4abd361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnvectionalBlocks(nn.Module):\n",
    "    def __init__(self, Input_channel, Output_channel, kernel_size=3, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # First convolutional layer:\n",
    "        # the constrcutor will have input channel, output channel, kernel size and dropout rate as parameters.\n",
    "        self.conv1 = nn.Conv1d(in_channels=Input_channel, out_channels=Output_channel, kernel_size=kernel_size, padding= kernel_size//2)\n",
    "        # Batch normalization:\n",
    "        self.bn1 = nn.BatchNorm1d(Output_channel)\n",
    "        self.drop = nn.Dropout1d(p=dropout_rate)\n",
    "\n",
    "\n",
    "# OPERATION FUNCTION:\n",
    "# Extrating the local patters \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "#     \n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # First convolutional block\n",
    "        self.conv_block1 = ConnvectionalBlocks(Input_channel=6, Output_channel=32, kernel_size=5, dropout_rate=0.1)\n",
    "        # Second convolutional block\n",
    "        self.conv_block2 = ConnvectionalBlocks(Input_channel=32, Output_channel= 32, kernel_size=4, dropout_rate=0.1)\n",
    "        # Max pooling, to halve the lengh\n",
    "        self.pool1  = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv_block3 = ConnvectionalBlocks(Input_channel=32, Output_channel=64, kernel_size=5, dropout_rate=0.1)\n",
    "        # Fourth convolutional block\n",
    "        self.conv_block4 = ConnvectionalBlocks(Input_channel=64, Output_channel=64, kernel_size=4, dropout_rate=0.1)\n",
    "        # second Max pooling\n",
    "        self.pool2  = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        # Global average pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "\n",
    "\n",
    "# Operation function:   \n",
    "    def forward(self, x):\n",
    "        # Switching the input index\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.squeeze(-1)\n",
    "        logits = self.fc1(x)\n",
    "        return logits\n",
    "\n",
    "model = CNNModel().to(device)\n",
    "\n",
    "\n",
    "# Sources :\n",
    "# https://medium.com/@ugamakelechi501/building-a-convolutional-neural-network-cnn-from-scratch-with-pytorch-eca3ffdcf2ff\n",
    "# https://www.dkneup.com/blog/cnn-time-series-forecasting-in-tensorflow-pytorch\n",
    "# https://medium.com/%40santi.pdp/how-pytorch-transposed-convs1d-work-a7adac63c4a5\n",
    "\n",
    "# For debugging, I used the Qwen3 Max model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38269df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As in the Keras notebook, calculating class weights does not work well here.\n",
    "#The gap between training and validation loss is big because the Occupancy distribution is different in each dataset.\n",
    "# The model is trained on the train dataset distribution but evaluated on the validation dataset distribution.\n",
    "\n",
    "#I should go with the same approach as in the Keras notebook: use Focal Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c174a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Focal Loss class:\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=3.0):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        targets = targets.float()\n",
    "        binary_class_loss= F.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
    "        probability_true_class = torch.exp(-binary_class_loss)\n",
    "        loss = (1- probability_true_class).pow(self.gamma) * binary_class_loss\n",
    "        return loss.mean()\n",
    "criterion = FocalLoss(gamma=3.0)\n",
    "\n",
    "# The loss class, calculates loss with 1 class's weight.\n",
    "\n",
    "# Sources:\n",
    "# https://discuss.pytorch.org/t/implementing-focal-loss-for-a-binary-classification-problem/128664\n",
    "# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6454a297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 1e-06\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.000001)\n",
    "# If val loss does not improve for 5 epochs, lr is going to be cut by half\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3, mode='min' )\n",
    "print('Optimizer:', optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b76697",
   "metadata": {},
   "source": [
    "<h2><center>Training Loop<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b122cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate F2 score\n",
    "def f2_score(y_true, y_pred):\n",
    "    from sklearn.metrics import fbeta_score\n",
    "    return fbeta_score(y_true, y_pred,beta=2.0, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f13f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: TrLoss 0.0311, VaLoss 0.0254, Acc 0.9178, AP 0.9121, Rec 0.9627, Prec 0.8558, F2 0.9392, LR 0.001000\n",
      "Model saved (F2:0.9392)\n",
      "Epoch   2: TrLoss 0.0169, VaLoss 0.0210, Acc 0.9533, AP 0.9466, Rec 0.9693, Prec 0.8929, F2 0.9530, LR 0.001000\n",
      "Model saved (F2:0.9530)\n",
      "Epoch   3: TrLoss 0.0147, VaLoss 0.0203, Acc 0.9605, AP 0.9598, Rec 0.9430, Prec 0.8903, F2 0.9319, LR 0.001000\n",
      "Epoch   4: TrLoss 0.0139, VaLoss 0.0195, Acc 0.9598, AP 0.9627, Rec 0.9331, Prec 0.8911, F2 0.9244, LR 0.001000\n",
      "Epoch   5: TrLoss 0.0130, VaLoss 0.0197, Acc 0.9626, AP 0.9579, Rec 0.9221, Prec 0.9161, F2 0.9209, LR 0.001000\n",
      "Epoch   6: TrLoss 0.0119, VaLoss 0.0164, Acc 0.9651, AP 0.9695, Rec 0.9320, Prec 0.9372, F2 0.9330, LR 0.001000\n",
      "Epoch   7: TrLoss 0.0119, VaLoss 0.0175, Acc 0.9634, AP 0.9574, Rec 0.9035, Prec 0.9364, F2 0.9099, LR 0.001000\n",
      "Epoch   8: TrLoss 0.0121, VaLoss 0.0280, Acc 0.9664, AP 0.9348, Rec 0.9156, Prec 0.8599, F2 0.9039, LR 0.001000\n",
      "Epoch   9: TrLoss 0.0120, VaLoss 0.0176, Acc 0.9662, AP 0.9567, Rec 0.9090, Prec 0.9325, F2 0.9136, LR 0.001000\n",
      "Epoch  10: TrLoss 0.0117, VaLoss 0.0190, Acc 0.9685, AP 0.9558, Rec 0.9024, Prec 0.9216, F2 0.9062, LR 0.001000\n",
      "Early stopping triggered.\n",
      "\n",
      " Loaded best model with F2: 0.9530\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "best_val_loss =float('inf')\n",
    "best_f2 = 0.0\n",
    "patience = 8\n",
    "patience_counter = 0\n",
    "best_model_state= None\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train() \n",
    "    train_loss_sum= 0\n",
    "    correct_predictions = 0\n",
    "    train_total= 0\n",
    "    \n",
    "    for X_batch,y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch =y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs= model(X_batch)            \n",
    "        loss = criterion(outputs.squeeze(1), y_batch.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_sum += loss.item()*X_batch.size(0)\n",
    "        predictions =(torch.sigmoid(outputs.squeeze(1))>= 0.5).long()\n",
    "        correct_predictions += (predictions==y_batch).sum().item()\n",
    "        train_total += y_batch.size(0)\n",
    "\n",
    "    train_loss= train_loss_sum / len(train_dataset)\n",
    "    train_accuracy= correct_predictions/train_total\n",
    "\n",
    "# EVALUATION PHASE:\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_probabilities= []\n",
    "    val_predictions=[]\n",
    "    val_actual_class=[]\n",
    "      \n",
    "    with torch.no_grad():  \n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits= model(X_batch)\n",
    "            loss= criterion(logits.squeeze(1), y_batch.float())\n",
    "            val_loss_sum += loss.item()*X_batch.size(0)\n",
    "\n",
    "            probs=torch.sigmoid(logits.squeeze(1))\n",
    "            preds=(probs >=0.5).to(torch.int64)\n",
    "\n",
    "            val_predictions.extend(preds.tolist())\n",
    "            val_probabilities.extend(probs.tolist())  \n",
    "            val_actual_class.extend(y_batch.tolist())\n",
    "            \n",
    "    val_loss= val_loss_sum/len(val_dataset)\n",
    "\n",
    "# COMPUTE METRICS:\n",
    "    val_ap = average_precision_score(val_actual_class, val_probabilities)\n",
    "    val_recall= recall_score(val_actual_class, val_predictions, zero_division=0)\n",
    "    val_precision =precision_score(val_actual_class,val_predictions, zero_division=0)\n",
    "    val_f2 = f2_score(val_actual_class, val_predictions)\n",
    "\n",
    "\n",
    "\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch:>3}: \"\n",
    "          f\"TrLoss {train_loss:.4f},VaLoss {val_loss:.4f}, \"\n",
    "          f\"Acc {train_accuracy:.4f},AP {val_ap:.4f}, \"\n",
    "          f\"Rec {val_recall:.4f}, Prec {val_precision:.4f}, F2 {val_f2:.4f}, \"\n",
    "          f\"LR {current_lr:.6f}\")\n",
    "\n",
    "    if val_f2 > best_f2:\n",
    "        best_f2 = val_f2\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state= model.state_dict().copy()\n",
    "        print(f\"Model saved (F2:{val_f2:.4f})\")\n",
    "    else:\n",
    "        patience_counter+= 1\n",
    "        if patience_counter>=patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\n Loaded best model with F2: {best_f2:.4f}\")\n",
    "else:\n",
    "    print(\"\\nThe best model is not saved.\")\n",
    "\n",
    "# Source: https://docs.pytorch.org/tutorials/beginner/introyt/trainingyt.html   \n",
    "# For debugging, I used the Qwen3 Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695921f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30         0.8268       1.0000       0.9598      \n",
      "0.35         0.8539       1.0000       0.9669      \n",
      "0.40         0.8758       0.9978       0.9708      \n",
      "0.45         0.8902       0.9868       0.9659      \n",
      "0.50         0.9216       0.9024       0.9062      \n",
      "0.55         0.9333       0.8136       0.8350      \n",
      "0.60         0.9501       0.7303       0.7657      \n",
      "------------------------------------------------------------\n",
      "Optimal threshold: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Defening threshold:\n",
    "# To catch better the 1 class, I am going to find the optimized threshold based on F2 score.\n",
    "\n",
    "model.eval()\n",
    "probabilities =[]\n",
    "true_labels= []\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in val_loader:\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_logits= model(batch_features)\n",
    "        batch_probabilities = torch.sigmoid(batch_logits.squeeze(1))\n",
    "        probabilities.extend(batch_probabilities.cpu().tolist())\n",
    "        true_labels.extend(batch_labels.tolist())\n",
    "probabilities_array = np.array(probabilities)\n",
    "true_labels_array= np.array(true_labels)\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f2_score = 0.0\n",
    "\n",
    "threshold_candidates=[0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "\n",
    "for current_threshold in threshold_candidates:\n",
    "    predictions=(probabilities_array >= current_threshold).astype(int)\n",
    "    precision=precision_score(true_labels_array, predictions, zero_division=0)\n",
    "    recall= recall_score(true_labels_array, predictions,zero_division=0)\n",
    "    f2_score =(1 + 4) * (precision * recall)/(4*precision+recall+0.00000000001)   \n",
    "    if f2_score > best_f2_score:\n",
    "        best_f2_score= f2_score\n",
    "        best_threshold = current_threshold\n",
    "    \n",
    "    print(f\"{current_threshold:<12.2f} {precision:<12.4f} {recall:<12.4f} {f2_score:<12.4f}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Optimal threshold:{best_threshold}\")\n",
    "\n",
    "# I could  implement this code in validation loop, this makes redundancy in my code.\n",
    "# Source\" https://medium.com/%40douglaspsteen/precision-recall-curves-d32e5b290248\n",
    "# https://scikit-learn.org/1.4/modules/model_evaluation.html?\n",
    "# https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/?\n",
    "# For debugging, I used Qwen Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36093e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.05\n",
      "Test AP Score: 0.87\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Occupancy       0.96      0.90      0.93      7668\n",
      "   Occupancy       0.70      0.86      0.77      1992\n",
      "\n",
      "    accuracy                           0.89      9660\n",
      "   macro avg       0.83      0.88      0.85      9660\n",
      "weighted avg       0.91      0.89      0.90      9660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test DS:\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_probs = []  \n",
    "test_targets = []\n",
    "test_loss_sum = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch,y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch=y_batch.to(device)\n",
    "        \n",
    "        logits= model(X_batch)\n",
    "        loss =criterion(logits.squeeze(1),y_batch.float())\n",
    "        probs =torch.sigmoid(logits.squeeze(1))\n",
    "       \n",
    "        preds =(probs>= best_threshold).to(torch.int64)\n",
    "        test_loss_sum+=loss.item()*X_batch.size(0)\n",
    "\n",
    "        test_preds.extend(preds.tolist())\n",
    "        test_probs.extend(probs.tolist())\n",
    "        test_targets.extend(y_batch.tolist())\n",
    "\n",
    "test_loss=test_loss_sum/len(test_dataset)\n",
    "test_preds = np.array(test_preds)\n",
    "test_probs=np.array(test_probs)\n",
    "test_targets= np.array(test_targets)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.2f}\")\n",
    "print(f\"Test AP Score: {average_precision_score(test_targets,test_probs):.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "Confusion_matrix = confusion_matrix(test_targets, test_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "sns.heatmap(Confusion_matrix,annot=True, fmt='d',cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_targets, test_preds, target_names=['No Occupancy', 'Occupancy'],zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112487f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this Pytorch, I got better prediction's accuracy and balance  than Keras, but the problem is that the actual catches rate is lower than Keras.\n",
    "# My model misses more actual cases for occupancy.\n",
    "\n",
    "# One solution can be using resampling or oversampling, to make the distribution more similar.\n",
    "# Usually the val loss is a lot higher than train loss, which means the model is overfitting, but in my case, each DS has different distribution.\n",
    "\n",
    "\n",
    "# When I played with gamma parameter in Focal Loss class, I noticed that when gamma is higher, the recall becomes higher for 1 \n",
    "# But precision becames lower and also all the metrics for class 0 became lower. \n",
    "# But when gamma is lower, the precision becomes higher for class 1, but recall becomes lower. Also  all the metrics for class 0 became better.\n",
    "\n",
    "# I asked GPT and what  I learned: \n",
    "# When the gamma is higher, the model puts more focus on 1 class and becomes good to detects 1 that is why the recall is higher\n",
    "# while the model is fucusing on 1, it kind of ignores 0. \n",
    "#  I went for gamma = 3 which is not too high and not too low.\n",
    "\n",
    "\n",
    "\n",
    "# I picked up higher values for kernal size that model can see longet pattern.\n",
    "# the recall and f1 score are improved, the model can catch the 1 classes even with low confident.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a74d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
