{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff13fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b6a75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccebe953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Humidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupancy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Minute",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ec4cf616-f87c-4539-9f67-0875894e5538",
       "rows": [
        [
         "0",
         "21.76",
         "31.13333",
         "1",
         "14",
         "48"
        ],
        [
         "1",
         "21.79",
         "31.0",
         "1",
         "14",
         "49"
        ],
        [
         "2",
         "21.77",
         "31.1225",
         "1",
         "14",
         "50"
        ],
        [
         "3",
         "21.77",
         "31.1225",
         "1",
         "14",
         "51"
        ],
        [
         "4",
         "21.79",
         "31.13333",
         "1",
         "14",
         "51"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.76</td>\n",
       "      <td>31.13333</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.79</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.77</td>\n",
       "      <td>31.12250</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.77</td>\n",
       "      <td>31.12250</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.79</td>\n",
       "      <td>31.13333</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Occupancy  Hour  Minute\n",
       "0        21.76  31.13333          1    14      48\n",
       "1        21.79  31.00000          1    14      49\n",
       "2        21.77  31.12250          1    14      50\n",
       "3        21.77  31.12250          1    14      51\n",
       "4        21.79  31.13333          1    14      51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the DSs \n",
    "df_test = pd.read_csv('cleaned_datatest.csv')\n",
    "df_val = pd.read_csv('datavalidation.csv')\n",
    "df_train = pd.read_csv('datatraining.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3162e4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9752, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3f1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.duplicated().sum()\n",
    "df_train = df_train.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c810c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.duplicated().sum()\n",
    "df_val = df_val.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3da0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.duplicated().sum()\n",
    "df_test = df_test.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2485e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2526, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c0e6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7625, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a3d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (9249, 4) (2526, 4) (7625, 4)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into X and y\n",
    "X_train = df_train.drop('Occupancy', axis=1).values\n",
    "y_train = df_train['Occupancy'].values\n",
    "X_val = df_val.drop('Occupancy', axis=1).values\n",
    "y_val = df_val['Occupancy'].values\n",
    "X_test = df_test.drop('Occupancy', axis=1).values\n",
    "y_test = df_test['Occupancy'].values\n",
    "\n",
    " # Column index for minute and hour\n",
    "time_columns = [2, 3]\n",
    "# First and second columns are continuous\n",
    "continuous_columns = [0, 1]\n",
    "\n",
    "# Scaling oonly first two columns\n",
    "scaler = StandardScaler()\n",
    "X_train[:, continuous_columns] = scaler.fit_transform(X_train[:, continuous_columns])\n",
    "X_test[:, continuous_columns]  = scaler.transform(X_test[:, continuous_columns])\n",
    "X_val[:, continuous_columns]  = scaler.transform(X_val[:, continuous_columns])\n",
    "\n",
    "time_scaler = MinMaxScaler()\n",
    "X_train[:, time_columns] = time_scaler.fit_transform(X_train[:, time_columns])\n",
    "X_test[:, time_columns]  = time_scaler.transform(X_test[:, time_columns])\n",
    "X_val[:, time_columns]  = time_scaler.transform(X_val[:, time_columns])\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2edb1e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Scaling :\n",
      " [[0.72887849 0.32646912 0.60869565 0.81355932]\n",
      " [0.7582453  0.2927464  0.60869565 0.83050847]\n",
      " [0.73866743 0.32372993 0.60869565 0.84745763]] \n",
      "Labels: [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's see some values\n",
    "print(\"After Scaling :\\n\", X_train[:3], \"\\nLabels:\", y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f0cb850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences shape: (9189, 60, 4)\n",
      "Training class shape: (9189,)\n",
      "Example  X: [[0.72887849 0.32646912 0.60869565 0.81355932]\n",
      " [0.7582453  0.2927464  0.60869565 0.83050847]\n",
      " [0.73866743 0.32372993 0.60869565 0.84745763]\n",
      " [0.73866743 0.32372993 0.60869565 0.86440678]\n",
      " [0.7582453  0.32646912 0.60869565 0.86440678]\n",
      " [0.72887849 0.35850735 0.60869565 0.89830508]\n",
      " [0.7582453  0.34269943 0.60869565 0.91525424]\n",
      " [0.7582453  0.39223007 0.60869565 0.93220339]\n",
      " [0.7582453  0.37305064 0.60869565 0.93220339]\n",
      " [0.7582453  0.40993495 0.60869565 0.96610169]\n",
      " [0.7582453  0.42553294 0.60869565 0.96610169]\n",
      " [0.7582453  0.43817927 0.60869565 0.98305085]\n",
      " [0.7582453  0.39265246 0.65217391 0.        ]\n",
      " [0.7582453  0.39202014 0.65217391 0.01694915]\n",
      " [0.7582453  0.41920977 0.65217391 0.03389831]\n",
      " [0.78761212 0.41920977 0.65217391 0.05084746]\n",
      " [0.78761212 0.41225428 0.65217391 0.06779661]\n",
      " [0.85613469 0.44450244 0.65217391 0.06779661]\n",
      " [0.7582453  0.43185611 0.65217391 0.10169492]\n",
      " [0.78761212 0.47738292 0.65217391 0.11864407]\n",
      " [0.82676787 0.47548597 0.65217391 0.13559322]\n",
      " [0.85613469 0.48117682 0.65217391 0.13559322]\n",
      " [0.85613469 0.48686767 0.65217391 0.16949153]\n",
      " [0.85613469 0.49255852 0.65217391 0.18644068]\n",
      " [0.85613469 0.49255852 0.65217391 0.22033898]\n",
      " [0.85613469 0.5178512  0.65217391 0.23728814]\n",
      " [0.85613469 0.5178512  0.65217391 0.25423729]\n",
      " [0.85613469 0.51152803 0.65217391 0.27118644]\n",
      " [0.85613469 0.49255852 0.65217391 0.27118644]\n",
      " [0.85613469 0.51152803 0.65217391 0.28813559]\n",
      " [0.85613469 0.47738292 0.65217391 0.3220339 ]\n",
      " [0.85613469 0.47548597 0.65217391 0.33898305]\n",
      " [0.85613469 0.46979512 0.65217391 0.3559322 ]\n",
      " [0.85613469 0.46853048 0.65217391 0.37288136]\n",
      " [0.85613469 0.43607239 0.65217391 0.38983051]\n",
      " [0.85613469 0.43185611 0.65217391 0.38983051]\n",
      " [0.85613469 0.38380003 0.65217391 0.40677966]\n",
      " [0.85613469 0.32436224 0.65217391 0.44067797]\n",
      " [0.85613469 0.33068541 0.65217391 0.45762712]\n",
      " [0.85613469 0.30876425 0.65217391 0.47457627]\n",
      " [0.85613469 0.23457325 0.65217391 0.49152542]\n",
      " [0.85613469 0.23394093 0.65217391 0.49152542]\n",
      " [0.85613469 0.27883543 0.65217391 0.50847458]\n",
      " [0.85613469 0.2402641  0.65217391 0.54237288]\n",
      " [0.85613469 0.23457325 0.65217391 0.55932203]\n",
      " [0.85613469 0.24089642 0.65217391 0.57627119]\n",
      " [0.85613469 0.24658727 0.65217391 0.59322034]\n",
      " [0.85613469 0.20422204 0.65217391 0.61016949]\n",
      " [0.85613469 0.2288824  0.65217391 0.61016949]\n",
      " [0.85613469 0.23288623 0.65217391 0.6440678 ]\n",
      " [0.85613469 0.23457325 0.65217391 0.66101695]\n",
      " [0.85613469 0.15237206 0.65217391 0.6779661 ]\n",
      " [0.85613469 0.18314566 0.65217391 0.6779661 ]\n",
      " [0.85613469 0.16628303 0.65217391 0.71186441]\n",
      " [0.85613469 0.18525254 0.65217391 0.71186441]\n",
      " [0.85613469 0.19157571 0.65217391 0.72881356]\n",
      " [0.85613469 0.17892937 0.65217391 0.76271186]\n",
      " [0.82676787 0.17892937 0.65217391 0.77966102]\n",
      " [0.85613469 0.19157571 0.65217391 0.79661017]\n",
      " [0.85613469 0.12581475 0.65217391 0.81355932]]\n",
      "Example  y: 1\n"
     ]
    }
   ],
   "source": [
    "# MAKING SEQUENCES:\n",
    "\n",
    "window_size = 60\n",
    "# I need to create a function for making windows\n",
    "def time_windows(X, y, window_size, step_ahead = 1):\n",
    "    # Creating two list for features and labels\n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "    for i in range(0, len(X) - window_size - step_ahead + 1):\n",
    "        X_windows.append(X[i:i+window_size])\n",
    "        # so the next step after the window must be predicted\n",
    "        # if window_size from 0 to 30, the next step is 30\n",
    "        y_windows.append(y[i+window_size-1 + step_ahead])\n",
    "    return np.array(X_windows), np.array(y_windows)\n",
    "# Applying the function:\n",
    "X_train, y_train = time_windows(X_train, y_train, window_size)\n",
    "X_val, y_val = time_windows(X_val, y_val, window_size)\n",
    "X_test, y_test = time_windows(X_test, y_test, window_size)\n",
    "\n",
    "print('Training sequences shape:', X_train.shape)\n",
    "print('Training class shape:', y_train.shape)\n",
    "print('Example  X:', X_train[0])\n",
    "print(\"Example  y:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11013871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 class weight: tensor([3.7075])\n"
     ]
    }
   ],
   "source": [
    "zero_count = (y_train == 0).sum()\n",
    "one_count = (y_train == 1).sum()\n",
    "one_weight = torch.tensor([zero_count / max(one_count, 1)], dtype=torch.float32).to(device)\n",
    "print(\"1 class weight:\", one_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b86ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long) \n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test= torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test= torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4abd361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OccupancyCNN(\n",
       "  (conv1): Conv1d(4, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=480, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (drop_conv): Dropout(p=0.5, inplace=False)\n",
       "  (drop_fc): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OccupancyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(16)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(32)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.fc1   = nn.Linear(32 * 15, 64)  \n",
    "        self.fc2   = nn.Linear(64, 1)\n",
    "        self.drop_conv = nn.Dropout(p=0.5)  \n",
    "        self.drop_fc   = nn.Dropout(p=0.5) \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.transpose(1, 2)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop_conv(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop_conv(x)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop_fc(x)\n",
    "        x = self.fc2(x)       \n",
    "        return x\n",
    "model = OccupancyCNN().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6454a297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: BCEWithLogitsLoss()\n",
      "Loss function: BCEWithLogitsLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0005\n",
      "    maximize: False\n",
      "    weight_decay: 5e-06\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=one_weight)\n",
    "print('Loss function:', criterion)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.000005)\n",
    "# If val loss does not improve for 5 epochs, lr is going to be cut by half\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "print('Loss function:', criterion)\n",
    "print('Optimizer:', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7871d1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 4, 3], expected input[128, 60, 4] to have 4 channels, but got 60 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), y_batch\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\ML&DE\\Deep_Learning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ML&DE\\Deep_Learning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[15], line 21\u001b[0m, in \u001b[0;36mOccupancyCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#x = x.transpose(1, 2)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[0;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n",
      "File \u001b[1;32md:\\ML&DE\\Deep_Learning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ML&DE\\Deep_Learning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\ML&DE\\Deep_Learning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:371\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ML&DE\\Deep_Learning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:366\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    356\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    357\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    365\u001b[0m     )\n\u001b[1;32m--> 366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 4, 3], expected input[128, 60, 4] to have 4 channels, but got 60 channels instead"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)            \n",
    "        loss = criterion(outputs.squeeze(1), y_batch.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        preds = (torch.sigmoid(outputs) >= 0.5).float() \n",
    "        correct += (preds.squeeze() == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = correct / total\n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "    model.eval()  \n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    with torch.no_grad():  \n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits.squeeze(1), y_batch.float())\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "\n",
    "            probs = torch.sigmoid(logits.squeeze(1))\n",
    "            preds = (probs >= 0.5).to(torch.int64)\n",
    "\n",
    "\n",
    "            val_preds.extend(preds)\n",
    "            val_targets.extend(y_batch)\n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "\n",
    "\n",
    "    \n",
    "    # Convert predictions and targets to numpy for calculations\n",
    "    val_preds = np.array(val_preds)\n",
    "    val_targets = np.array(val_targets)\n",
    "    val_acc = accuracy_score(val_targets, val_preds)\n",
    "    val_prec = precision_score(val_targets, val_preds, pos_label=1.0, zero_division=0)\n",
    "    val_rec = recall_score(val_targets, val_preds, pos_label=1.0, zero_division=0)\n",
    "    val_f1 = f1_score(val_targets, val_preds, pos_label=1.0, zero_division=0)\n",
    "    learning_rate = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Print metrics for this epoch\n",
    "    print(f\"Epoch {epoch:2d}/{epochs} - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.3f} - \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.3f}, \"\n",
    "          f\"Prec: {val_prec:.3f}, Rec: {val_rec:.3f}, F1: {val_f1:.3f} - \"\n",
    "          f\"Learning Rate: {learning_rate:.6f}\")\n",
    "    scheduler.step(val_loss)\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        \n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "if patience_counter >= patience:\n",
    "    model.load_state_dict(best_model_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36093e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_targets = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits.squeeze(1), y_batch.float())\n",
    "        probs = torch.sigmoid(logits.squeeze(1))\n",
    "        preds = (probs >= 0.5).to(torch.int64)\n",
    "        val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        test_preds.extend(preds)\n",
    "        test_targets.extend(y_batch)\n",
    "test_preds = np.array(test_preds)\n",
    "test_targets = np.array(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf49ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAGdCAYAAABDxkoSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMJpJREFUeJzt3Xl8VPW9//F31mEzCRGSScoiyBWIbDVoGC0UJE1AtFLRFkUWRSncwP1BFDAtIqI1BdxAtuuCoEALXAtVcgViEFIlLKaGJbLIYoPChDUJBJgsM78/uIzMYTk5NmGCvp73cR5lzvnOyXd4yCPv+/l8v2cCPB6PRwAAABYE+nsCAADg+kOAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFgW7O8JXHBmymP+ngJQ64QMfdbfUwBqpZBGLWv0/uXH9lfbvWp6rv5SawIEAAC1hrvS3zOo9WhhAAAAy6hAAABg5HH7ewa1HgECAAAjNwHCDAECAAADDxUIU6yBAAAAllGBAADAiBaGKQIEAABGtDBM0cIAAACWUYEAAMCIB0mZIkAAAGBEC8MULQwAAGAZFQgAAIzYhWGKAAEAgAEPkjJHCwMAAFhGBQIAACNaGKYIEAAAGNHCMEWAAADAiOdAmGINBAAAsIwKBAAARrQwTBEgAAAwYhGlKVoYAADAMioQAAAY0cIwRYAAAMCIFoYpWhgAAMAyKhAAABh4PDwHwgwBAgAAI9ZAmKKFAQAALKMCAQCAEYsoTREgAAAwooVhigABAIARX6ZlijUQAADAMioQAAAY0cIwRQUCAAAjt7v6DgvmzJmjDh06KCwsTGFhYXI4HPr444+918+dO6eUlBTdeOONatCggfr166fCwkKfexQUFKhPnz6qV6+eoqKiNHbsWFVUVPiMWbdunW677TbZbDa1atVK8+fPt/xXRIAAAKCWaNKkif785z8rNzdXX3zxhe6++27df//9ys/PlySNGTNGH330kZYtW6b169fr0KFDeuCBB7zvr6ysVJ8+fVRWVqYNGzZowYIFmj9/viZOnOgdc+DAAfXp00c9evRQXl6eRo8erSeeeEKrV6+2NNcAj8fjqZ6P/e85M+Uxf08BqHVChj7r7ykAtVJIo5Y1ev9zOX+ptnvVcTz8b70/MjJS06ZN04MPPqjGjRtr8eLFevDBByVJu3btUtu2bZWTk6MuXbro448/1r333qtDhw4pOjpakjR37lyNHz9eR48eVWhoqMaPH6+MjAzt2LHD+zP69++voqIirVq1qsrzogIBAICRn1oYF6usrNRf//pXlZaWyuFwKDc3V+Xl5UpMTPSOadOmjZo1a6acnBxJUk5Ojtq3b+8ND5KUnJyskpISbxUjJyfH5x4Xxly4R1WxiBIAgBrkcrnkcrl8ztlsNtlstsuO3759uxwOh86dO6cGDRpo+fLliouLU15enkJDQxUREeEzPjo6Wk6nU5LkdDp9wsOF6xeuXW1MSUmJzp49q7p161bpc1GBAADAqBorEOnp6QoPD/c50tPTr/ijW7durby8PG3atEkjRozQ4MGD9dVXX13DD181VCAAADCozm/jTEtLU2pqqs+5K1UfJCk0NFStWrWSJMXHx2vLli2aPn26fve736msrExFRUU+VYjCwkLZ7XZJkt1u1+bNm33ud2GXxsVjjDs3CgsLFRYWVuXqg0QFAgCAGmWz2bzbMi8cVwsQRm63Wy6XS/Hx8QoJCVFWVpb32u7du1VQUCCHwyFJcjgc2r59u44cOeIdk5mZqbCwMMXFxXnHXHyPC2Mu3KOqqEAAAGDkpy/TSktLU+/evdWsWTOdOnVKixcv1rp167R69WqFh4dr6NChSk1NVWRkpMLCwjRq1Cg5HA516dJFkpSUlKS4uDgNHDhQU6dOldPp1IQJE5SSkuINLcOHD9fMmTM1btw4Pf7441q7dq2WLl2qjIwMS3MlQAAAYOSnJ1EeOXJEgwYN0uHDhxUeHq4OHTpo9erV+tWvfiVJeu211xQYGKh+/frJ5XIpOTlZs2fP9r4/KChIK1eu1IgRI+RwOFS/fn0NHjxYkydP9o5p0aKFMjIyNGbMGE2fPl1NmjTR22+/reTkZEtz5TkQQC3GcyCAy6vp50CczXqz2u5Vt+ewartXbcIaCAAAYBktDAAAjPgyLVMECAAAjPy0iPJ6QgsDAABYRgUCAAAjWhimCBAAABjRwjBFCwMAAFhGBQIAACMqEKYIEAAAGLEGwhQtDAAAYBkVCAAAjGhhmCJAAABgRAvDFAECAAAjKhCmWAMBAAAsowIBAIARLQxTBAgAAIxoYZiihQEAACyjAgEAgBEVCFMECAAAjDwef8+g1qOFAQAALKMCAQCAES0MUwQIAACMCBCmaGEAAADLqEAAAGDEg6RMESAAADCihWGKAAEAgBHbOE2xBgIAAFhGBQIAACNaGKYIEAAAGBEgTNHCAAAAllGBAADAiG2cpggQAAAYeNzswjBDCwMAAFhGBQIAACMWUZoiQAAAYMQaCFO0MAAAgGVUIAAAMGIRpSkCBAAARqyBMEWAAADAiABhijUQAADAMioQAAAY8XXepggQPzLBXfoo6JZ4BUbapYpyVX63V+Xrl8lzwukdY3t4vIKatfF5X/mXn6p8zXve1/XGv3vJvV0fzlHlzs3f/6yf363g+J4KCGskT8lxleesVGX+hhr4VMC/76/LV2rJ8gwdOlwoSWrVormGP/aIujpulyQ9P3WGcrZ8qaPHTqhevTrq1C5OY/7zcbVs3lSStOvr/Xpn4VL9c1u+iopKFBsTrd/2vUcDf9vX+zOOHjuhaTPfUv6ur1Xw7SENePDXemb08Gv+WVENaGGYIkD8yAQ1ba2Kf2bJ7TwgBQQp9Jf9ZPvtUzr3zh+l8jLvuIq8dSr7bPn3b7zo2gWujLdVeWD79yfOnfH+MbhTD4X88kGVrZov9+EDCoxtodDkISo7V6rKfVtr5LMB/w5740YaM/wxNW/6M3k8Hv3940806pnJ+p93Z6pVy+aKa91KfZJ6KCY6SsUlpzT7nYUaNuaPWr3sXQUFBemr3V8rsmGE/jxxrOxRjZW3Y6eenzJDQYGBeuTBX0uSysrL1TAiXMMG99f7S5abzAi4vhEgfmRcy171fZ3xjur91wwFRt8k97d7vOc9FWVSaYnJzc5ccUxQuztVkbdOlbvOVyQqi4+qwt5CwV3uIUCgVur+iy4+r//f74doyfIMbc3fpVYtm+uh++/xXvtZTLRGDRusfoP/U98dLlSzJrF64N5kn/c3/VmMtu7YqU/Wb/AGiJ/FRCvt/yoOyzPW1PAnQo1iG6cpAsSPXICtriTJc67U53xwnEPBcQ55SotVuXeryjd8KFX4ViFCfjVQob0ek7vo6PmwsP0f3983KFiqLPf9YRXlCoxpKQUGSe7KmvlAQDWorKzU6k//obPnzqlTuzaXXD9z9pxWZKxRk1i7YqIbX/E+p06XKjysQU1OFf7CkyhNWQ4Qx44d07x585STkyOn83xf3W63684779SQIUPUuPGV/7HhWgtQaM+HVfntHnmOfec9W/HVRnlKjstzqkiBUU0U0v0hBUTaVbZipndM2T/+Jve/dspTXqagFu0UmjRQ5aE2VeR+IkmqPLBDwR26qWLPP+Up/JcC7TcpuEO388GibgOptPiaf1rAzJ59BzTg96kqKytTvbp1Nf2lZ3Vzi+be63/920q9MvsdnT17Ti2aNdGbr/1JISEhl73Xl9u/0uqsbM2a9vy1mj5Qq1gKEFu2bFFycrLq1aunxMRE3XLLLZKkwsJCzZgxQ3/+85+1evVqde7c+ar3cblccrlcPucqKyplCw6yOH1cTUjSowpo3ESuRS/5nK/cuv77Px/7Vp7Txarz8DiVRzSWp+ioJKliw0feMRVHChQQEqrgO3p7A0T5hg8VUD9cdQZOkAIC5CktUcWOzxXS5R5WL6PWatGsiT6YP0unTpdqzaef6Y9/ekXzZ071hog+ST3kuP3nOnr8hOYv/kBPT0zX+3Nekc0W6nOfr/d/o/965nmNeHyA7kqI98dHQU2jhWHKUoAYNWqUHnroIc2dO1cBAQE+1zwej4YPH65Ro0YpJyfnqvdJT0/X88/7pvY/9OyoP/7q51amg6sISXxUQTd3kmtxujynTl51rPvwPklSQMNob4Awqjy0XyF33S8FBUuVFVJFuco+nietXqCA+mHynC5ScMfu8rjOSmdOVfvnAapDSEiImjWJlSTd2uY/lL9rjxYu+7ueG/dfkqQbGtTXDQ3qq3nTn6njrW10Z6+HlJW9Qff8qrv3HvsO/EtD/ytND/66t34/5GF/fAxcAx52YZiy9CCprVu3asyYMZeEB0kKCAjQmDFjlJeXZ3qftLQ0FRcX+xxP9+hgZSq4ipDERxV0y21y/XWqPMXHTMcHRjWTJHlOF115THQzec6ePh8eLuauPB9QPB4Ftb3j/xZQktxxfXC7PSorK7/sNY/HI49HPtf37v+XHhv1jO7vnaj/9/sh12iWQO1kqQJht9u1efNmtWlz6aIjSdq8ebOio6NN72Oz2WSz2XzOnaF9US1CfjVQwXFd5PrbDHnKzkr1w85fcJ2VKsoVENFYQXFdVLlvm3T2tAKjmirk7odVWbBLnqPfSpKCbu4o1Q+X+9A+qaJcQTfdqpAu96piyyrvzwloGK3AmJZyH96vgDr1FHx7sgIbN9G5jLf98bEBU6/NeVddHZ0VEx2l0jNnlLFmnbZ8uU3//eqLOvjdYa3Kytadd9ymyIhwOY8e0zvvL5XNFqqud55/TsTX+7/R0FHP6M6EeA3u/xsdO35CkhQYGKjIhhHen7Nrz/mK3pkz53SyqFi79uxTSEiwz1oLXAdoYZiyFCCefvppDRs2TLm5uerZs6c3LBQWFiorK0tvvfWWXn755RqZKKom5La7JUl1HnnG57wr421V7vhcqqxUUPM4hXROkkJs8pScUOWeL1R+0ZoHj7tSobfdrYC7+59f33DyiMrX/lUVF62dUGCgQu5IVkCkXXJXqvJfu3Ru4Z/kKTl+TT4nYNWJoiL94YWXdfT4Cd1Qv75uadVC//3qi7rzjtt05Ohx/XPrDr2/dIVKTp3WjZER6tyxnRbOfVU3/l84WPPpZzpRVKyVq9dq5eq13vvG2qO05oMF3tcPPjbS++evdn+tjMx1l4zBdcBPuzDS09P1t7/9Tbt27VLdunV15513asqUKWrdurV3TPfu3bV+/Xqf9/3+97/X3Llzva8LCgo0YsQIffrpp2rQoIEGDx6s9PR0BQd//2t/3bp1Sk1NVX5+vpo2baoJEyZoyJAhVZ5rgMdjbcXbkiVL9Nprryk3N1eVlee36gUFBSk+Pl6pqan67W9/a+V2XmemPPaD3gf8mIUMfdbfUwBqpZBGLWv0/qWTB1TbvepPXFTlsb169VL//v11++23q6KiQn/4wx+0Y8cOffXVV6pfv76k8wHilltu0eTJk73vq1evnsLCzlecKysr1alTJ9ntdk2bNk2HDx/WoEGD9OSTT+qll84vqj9w4IDatWun4cOH64knnlBWVpZGjx6tjIwMJScnXzqxy7AcIC4oLy/XsWPn++uNGjW64lanqiJAAJciQACX92MNEEZHjx5VVFSU1q9fr27dukk6HyA6deqk119//bLv+fjjj3Xvvffq0KFD3k7B3LlzNX78eB09elShoaEaP368MjIytGPHDu/7+vfvr6KiIq1ateqy9zX6wd/GGRISopiYGMXExPzb4QEAgFrF7a62w+VyqaSkxOcwPsrgSoqLzz9TJzIy0uf8okWL1KhRI7Vr105paWk6c+b7rxrIyclR+/btfdYkJicnq6SkRPn5+d4xiYmJPvdMTk423UV5Mb7OGwAAI7en2o709HSFh4f7HOnp6eZTcLs1evRo3XXXXWrXrp33/COPPKKFCxfq008/VVpamt5//309+uij3utOp/OSDQ0XXl94AOSVxpSUlOjs2bNV+iviUdYAANSgtLQ0paam+pwz7kS8nJSUFO3YsUOfffaZz/lhw4Z5/9y+fXvFxMSoZ8+e2rdvn26++ebqmXQVECAAADCqxl0Yl3t0gZmRI0dq5cqVys7OVpMmTa46NiEhQZK0d+9e3Xzzzd5HLlyssPD819jb7Xbv/144d/GYsLAw1a1bt0pzpIUBAIBRNbYwrPB4PBo5cqSWL1+utWvXqkWLFqbvufAAx5iYGEmSw+HQ9u3bdeTIEe+YzMxMhYWFKS4uzjsmKyvL5z6ZmZlyOBxVnisBAgCAWiIlJUULFy7U4sWLdcMNN8jpdMrpdHrXJezbt08vvPCCcnNz9c033+jDDz/UoEGD1K1bN3XocP6JzklJSYqLi9PAgQO1detWrV69WhMmTFBKSoq3EjJ8+HDt379f48aN065duzR79mwtXbpUY8aMqfJcCRAAABh43O5qO6yYM2eOiouL1b17d+9Ox5iYGC1ZskSSFBoaqk8++URJSUlq06aNnnrqKfXr108fffT9wwCDgoK0cuVKBQUFyeFw6NFHH9WgQYN8nhvRokULZWRkKDMzUx07dtQrr7yit99+u8rPgJBYAwEAwKX89Chrs0czNW3a9JKnUF5O8+bN9b//+79XHdO9e3d9+eWXluZ3MSoQAADAMioQAAAY8WVapggQAAAY+enLtK4nBAgAAIyoQJhiDQQAALCMCgQAAAYeKhCmCBAAABgRIEzRwgAAAJZRgQAAwMjiEyR/iggQAAAY0cIwRQsDAABYRgUCAAAjKhCmCBAAABiYfakVaGEAAIAfgAoEAABGtDBMESAAADAiQJgiQAAAYMCjrM2xBgIAAFhGBQIAACMqEKYIEAAAGPEka1O0MAAAgGVUIAAAMGARpTkCBAAARgQIU7QwAACAZVQgAAAwYhGlKQIEAAAGrIEwRwsDAABYRgUCAAAjWhimCBAAABjQwjBHgAAAwIgKhCnWQAAAAMuoQAAAYOChAmGKAAEAgBEBwhQtDAAAYBkVCAAADGhhmCNAAABgRIAwRQsDAABYRgUCAAADWhjmCBAAABgQIMwRIAAAMCBAmGMNBAAAsIwKBAAARp4Af8+g1iNAAABgQAvDHC0MAABgGRUIAAAMPG5aGGYIEAAAGNDCMEcLAwAAWEYFAgAAAw+7MEwRIAAAMKCFYY4WBgAAtUR6erpuv/123XDDDYqKilLfvn21e/dunzHnzp1TSkqKbrzxRjVo0ED9+vVTYWGhz5iCggL16dNH9erVU1RUlMaOHauKigqfMevWrdNtt90mm82mVq1aaf78+ZbmSoAAAMDA4w6otsOK9evXKyUlRRs3blRmZqbKy8uVlJSk0tJS75gxY8boo48+0rJly7R+/XodOnRIDzzwgPd6ZWWl+vTpo7KyMm3YsEELFizQ/PnzNXHiRO+YAwcOqE+fPurRo4fy8vI0evRoPfHEE1q9enWV5xrg8Xg8lj5dDTkz5TF/TwGodUKGPuvvKQC1UkijljV6/4LOPavtXs2+yPrB7z169KiioqK0fv16devWTcXFxWrcuLEWL16sBx98UJK0a9cutW3bVjk5OerSpYs+/vhj3XvvvTp06JCio6MlSXPnztX48eN19OhRhYaGavz48crIyNCOHTu8P6t///4qKirSqlWrqjQ3KhAAABhUZwXC5XKppKTE53C5XFWaR3FxsSQpMjJSkpSbm6vy8nIlJiZ6x7Rp00bNmjVTTk6OJCknJ0ft27f3hgdJSk5OVklJifLz871jLr7HhTEX7lEVBAgAAGpQenq6wsPDfY709HTT97ndbo0ePVp33XWX2rVrJ0lyOp0KDQ1VRESEz9jo6Gg5nU7vmIvDw4XrF65dbUxJSYnOnj1bpc/FLgwAAAyq80mUaWlpSk1N9Tlns9lM35eSkqIdO3bos88+q7a5VCcCBAAABtW5OtBms1UpMFxs5MiRWrlypbKzs9WkSRPvebvdrrKyMhUVFflUIQoLC2W3271jNm/e7HO/C7s0Lh5j3LlRWFiosLAw1a1bt0pzpIUBAEAt4fF4NHLkSC1fvlxr165VixYtfK7Hx8crJCREWVnfL8zcvXu3CgoK5HA4JEkOh0Pbt2/XkSNHvGMyMzMVFhamuLg475iL73FhzIV7VAUVCAAADPz1ZVopKSlavHix/v73v+uGG27wrlkIDw9X3bp1FR4erqFDhyo1NVWRkZEKCwvTqFGj5HA41KVLF0lSUlKS4uLiNHDgQE2dOlVOp1MTJkxQSkqKtxIyfPhwzZw5U+PGjdPjjz+utWvXaunSpcrIyKjyXAkQAAAY+OtR1nPmzJEkde/e3ef8u+++qyFDhkiSXnvtNQUGBqpfv35yuVxKTk7W7NmzvWODgoK0cuVKjRgxQg6HQ/Xr19fgwYM1efJk75gWLVooIyNDY8aM0fTp09WkSRO9/fbbSk5OrvJceQ4EUIvxHAjg8mr6ORD72lX9F6mZm3dU/eFM1xMqEAAAGPBdGOYIEAAAGLj5Nk5T7MIAAACWUYEAAMDAX4sorycECAAADPy1jfN6QoAAAMCgduxPrN1YAwEAACyjAgEAgAEtDHMECAAADNjGaY4WBgAAsIwKBAAABmzjNEeAAADAgF0Y5mhhAAAAy6hAAABgwCJKcwQIAAAMWANhjhYGAACwjAoEAAAGLKI0R4AAAMCANRDmak2ACHt2jb+nANQ6M2eW+3sKQK00/ODCGr0/ayDMsQYCAABYVmsqEAAA1Ba0MMwRIAAAMGANpTlaGAAAwDIqEAAAGNDCMEeAAADAgF0Y5mhhAAAAy6hAAABg4Pb3BK4DBAgAAAw8ooVhhhYGAACwjAoEAAAGbh4EYYoAAQCAgZsWhikCBAAABqyBMMcaCAAAYBkVCAAADNjGaY4AAQCAAS0Mc7QwAACAZVQgAAAwoIVhjgABAIABAcIcLQwAAGAZFQgAAAxYRGmOAAEAgIGb/GCKFgYAALCMCgQAAAZ8F4Y5AgQAAAZ8Gac5AgQAAAZs4zTHGggAAGAZFQgAAAzcAayBMEOAAADAgDUQ5mhhAAAAy6hAAABgwCJKc1QgAAAwcAdU32FFdna27rvvPsXGxiogIEArVqzwuT5kyBAFBAT4HL169fIZc+LECQ0YMEBhYWGKiIjQ0KFDdfr0aZ8x27ZtU9euXVWnTh01bdpUU6dOtfx3RIAAAKCWKC0tVceOHTVr1qwrjunVq5cOHz7sPf7yl7/4XB8wYIDy8/OVmZmplStXKjs7W8OGDfNeLykpUVJSkpo3b67c3FxNmzZNkyZN0ptvvmlprrQwAAAw8NeTKHv37q3evXtfdYzNZpPdbr/stZ07d2rVqlXasmWLOnfuLEl64403dM899+jll19WbGysFi1apLKyMs2bN0+hoaG69dZblZeXp1dffdUnaJihAgEAgIGnGg+Xy6WSkhKfw+Vy/eC5rVu3TlFRUWrdurVGjBih48ePe6/l5OQoIiLCGx4kKTExUYGBgdq0aZN3TLdu3RQaGuodk5ycrN27d+vkyZNVngcBAgCAGpSenq7w8HCfIz09/Qfdq1evXnrvvfeUlZWlKVOmaP369erdu7cqKyslSU6nU1FRUT7vCQ4OVmRkpJxOp3dMdHS0z5gLry+MqQpaGAAAGFTn13mnpaUpNTXV55zNZvtB9+rfv7/3z+3bt1eHDh108803a926derZs+e/NU+rCBAAABhU5zZOm832gwODmZYtW6pRo0bau3evevbsKbvdriNHjviMqaio0IkTJ7zrJux2uwoLC33GXHh9pbUVl0MLAwAAg+pcA1GTvv32Wx0/flwxMTGSJIfDoaKiIuXm5nrHrF27Vm63WwkJCd4x2dnZKi8v947JzMxU69at1bBhwyr/bAIEAAC1xOnTp5WXl6e8vDxJ0oEDB5SXl6eCggKdPn1aY8eO1caNG/XNN98oKytL999/v1q1aqXk5GRJUtu2bdWrVy89+eST2rx5sz7//HONHDlS/fv3V2xsrCTpkUceUWhoqIYOHar8/HwtWbJE06dPv6TNYoYWBgAABtW5BsKKL774Qj169PC+vvBLffDgwZozZ462bdumBQsWqKioSLGxsUpKStILL7zg0yJZtGiRRo4cqZ49eyowMFD9+vXTjBkzvNfDw8O1Zs0apaSkKD4+Xo0aNdLEiRMtbeGUpACPx1MrvjMkOPRn/p4CUOvMjO5hPgj4CRp+cGGN3v+tJo9W272e/LZm5+ovtDAAAIBltDAAADDgy7TMESAAADDw+GkNxPWEFgYAALCMCgQAAAa0MMwRIAAAMCBAmKOFAQAALKMCAQCAQa14QFItR4AAAMDAX0+ivJ4QIAAAMGANhDnWQAAAAMuoQAAAYEAFwhwBAgAAAxZRmqOFAQAALKMCAQCAAbswzBEgAAAwYA2EOVoYAADAMioQAAAYsIjSHAECAAADNxHCFC0MAABgGRUIAAAMWERpjgABAIABDQxzBAgAAAyoQJhjDQQAALCMCgQAAAY8idIcAQIAAAO2cZqjhQEAACyjAgEAgAH1B3MECAAADNiFYY4WBgAAsIwKBAAABiyiNEeAAADAgPhgjhYGAACwjAoEAAAGLKI0R4AAAMCANRDmCBAAABgQH8yxBgIAAFhGBQIAAAPWQJgjQAAAYOChiWGKFgYAALCMCgQAAAa0MMwRIAAAMGAbpzlaGAAAwDIqEAAAGFB/MEcF4idg/LiRytmQoZPHd+vQt1v1wf+8o1tuufmScV0S4pW5eqmKT36tE8d26dOsD1SnTh3v9b17Nqqi7DufY9zYlGv5UYAfLCahtXrNS9XAL97Q8IMLdVNy/BXHdn3pMQ0/uFDthyZ7z93QpJF+Oe0JPfL5q3ri63l6+LNX1Dn1AQWGBPm8N7JNU93/wbN64ut5enTTdHUa3qfGPhNqjlueajt+rKhA/AR069pFc+Ys0Be5eQoODtaLk5/RxxmL1b5jd505c1bS+fCQsXKhpkydqf83ZoIqKirVoUOc3G7fpUTPTZqmt99Z5H196tTpa/pZgB8quK5Nx3cWaNfSbPV6a/QVx93Uq7Oib2ulUucJn/MRrWIVEBio7LR5Kv6mUJGtm+qXU4YquJ5NG1/8iyQppEFd3btovL79LF/ZafMU2aapur/8pFwlZ7Rz8ac1+fGAa44A8RPQ575HfV4//sRoOQ9tV/xtHfSPzzZJkl55eZJmzpqnqdNmecft2bPvknudOnVahYVHa3bCQA04uG6bDq7bdtUx9e0N9YvJg5Tx6BTdM//pq77/VMFRbW0Zo1sH9vQGiP/4zZ0KDA3WuqfflLu8Uif3fKdGcc3V4cneBIjrDLswzNHC+AkKDw+TJJ04WSRJatz4RiUk3KYjR47pH+v/ru8O5mntJ/+ju+68/ZL3jhubosLDO7Rl82o9lTpcQUFBl4wBrksBAbr79eHaOjdDJ/d8V6W3hIbV1bni76tw0be10uFNu+Qur/SeO7h+mxq2ilVoeL1qnzJqjqca/+/HigrET0xAQIBeffl5ff75ZuXn75YktWzRXJI08dmnNG78ZG3dlq+BAx7SmtVL1PHnPbV37wFJ0sxZ8/Tll9t14mSRHF06608vPqMYe7SeHve83z4PUF1+/p/3yl3p1vZ5q6s0PuymaLUbkqSNLy72nqsXFaFTBb4VurPHis9faxyhsuIz1Tdh1CgqEOaqvQJx8OBBPf7441cd43K5VFJS4nN4PD/elFabvDHjJd16a2s98uh/es8FBp7/z+CttxdqwXtLlZeXr6fGTtLuPfv02JDfece9Pv1Nrc/O0fbtO/XmW+9r7LjJSkl5TKGhodf8cwDVqVH7m9T+8WR9mvrfVRpf395Qfd4fp/0Zm7XzL+tqdnL4ScnOztZ9992n2NhYBQQEaMWKFT7XPR6PJk6cqJiYGNWtW1eJiYn6+uuvfcacOHFCAwYMUFhYmCIiIjR06FCdPu27Xm3btm3q2rWr6tSpo6ZNm2rq1KmW51rtAeLEiRNasGDBVcekp6crPDzc5/C4T1X3VGAw/fUX1eeeRCUmPaTvvjvsPX/YWShJ+mrnHp/xu3btVdOmP7vi/TZv+VIhISG66aamNTNh4BqJuaO16jYK06Mbp2vYgQUadmCBbmjaWI5nB2jAhtd8xtaLjtB9S/4g5xd7tH78Oz7XzhwpUt3GYT7n6jYKP3/taFGNfgZUL3+1MEpLS9WxY0fNmjXrstenTp2qGTNmaO7cudq0aZPq16+v5ORknTt3zjtmwIABys/PV2ZmplauXKns7GwNGzbMe72kpERJSUlq3ry5cnNzNW3aNE2aNElvvvmmpblabmF8+OGHV72+f/9+03ukpaUpNTXV51zDG9tYnQosmP76i+p7fy/1/NVD+uabgz7XvvnmoL777rBaG7Z2/sd/tNTq1Vde+NWx462qrKzUkSPHamTOwLWy54PP9e1n+T7n7l04Tns++Fy7lmZ7z9W3N9R9S/6go9u/0bqn3pQMldPCf+7VHeMeUmBwkNwV59dBNOnWXif3HqJ9cZ3xVwujd+/e6t2792WveTwevf7665owYYLuv/9+SdJ7772n6OhorVixQv3799fOnTu1atUqbdmyRZ07d5YkvfHGG7rnnnv08ssvKzY2VosWLVJZWZnmzZun0NBQ3XrrrcrLy9Orr77qEzTMWA4Qffv2VUBAwFVbDgEBAVe9h81mk81ms/Qe/HBvzHhJD/fvqwf6Pa5Tp04rOrqxJKm4+JQ3tb7y6lw9N/Epbd32lbZuzdeggQ+pTeub9bv+5/9j6pIQrzvu+LnWrd+gU6dOq0uXeL0ybZIWLf6bioqK/fbZgKoKrmdT+E3R3tdhTRvrxrhmchWV6vSh43IV+ZZ43eWVOnO0SMX7z1fr6tsb6tdL/6hT3x7TxhcXq86N31cazh49/29g74oN6jz6N/rltCeUN2elIls3UfvHk7Th+UXCT5fL5ZLL5fI5d7nfg2YOHDggp9OpxMRE77nw8HAlJCQoJydH/fv3V05OjiIiIrzhQZISExMVGBioTZs26Te/+Y1ycnLUrVs3n/ZzcnKypkyZopMnT6phw4ZVmo/lABETE6PZs2d7049RXl6e4uOv/IAWXHsjhg+WJK3N+sDn/ONDx+i995dKkma88bbq1LHplWmTFBkZoW3bvlKv3g9r//5/STr/D+B3v71fE59Nlc0WqgPfHNT0GW/ptdetlbwAf4nq0FK/XvZH7+s7nzu/vXn3smx9mmr+33GTru0U3sKu8BZ2Ddzyhs+1uU3P36vs1FmtHDBFXf80RP0yXtC5k6eV+/oKtnBeh9zVuC4vPT1dzz/vu9j8ueee06RJkyzdx+l0SpKio6N9zkdHR3uvOZ1ORUVF+VwPDg5WZGSkz5gWLVpcco8L12osQMTHxys3N/eKAcKsOoFrLzj0yusYLjZ12iyf50Bc7Mu8Hbqr633VOS3gmjq0caf3F31VLLpzjM/r3cv+od3L/mH6vhO7Durv/V6wPD/ULtX5W+xybXur1YfayHKAGDt2rEpLS694vVWrVvr0U9I2AADSD2tXXI7dbpckFRYWKiYmxnu+sLBQnTp18o45cuSIz/sqKip04sQJ7/vtdrsKCwt9xlx4fWFMVVjehdG1a1f16tXritfr16+vX/7yl1ZvCwBArVEbvwujRYsWstvtysrK8p4rKSnRpk2b5HA4JEkOh0NFRUXKzc31jlm7dq3cbrcSEhK8Y7Kzs1VeXu4dk5mZqdatW1e5fSHxJEoAAC7hr22cp0+fVl5envLy8iSdXziZl5engoICBQQEaPTo0XrxxRf14Ycfavv27Ro0aJBiY2PVt29fSVLbtm3Vq1cvPfnkk9q8ebM+//xzjRw5Uv3791dsbKwk6ZFHHlFoaKiGDh2q/Px8LVmyRNOnT7+kzWKGJ1ECAFBLfPHFF+rRo4f39YVf6oMHD9b8+fM1btw4lZaWatiwYSoqKtIvfvELrVq1yuebkxctWqSRI0eqZ8+eCgwMVL9+/TRjxgzv9fDwcK1Zs0YpKSmKj49Xo0aNNHHiREtbOCUpwFNLVjxWdaEf8FMyM7qH+SDgJ2j4wYU1ev/fNe9bbfda8q8V1Xav2oQKBAAABtW5duHHigABAIDBj/lbNKsLiygBAIBlVCAAADDg67zNESAAADCoJfsLajVaGAAAwDIqEAAAGLALwxwBAgAAA9ZAmKOFAQAALKMCAQCAAc+BMEeAAADAgDUQ5mhhAAAAy6hAAABgwHMgzBEgAAAwYBeGOQIEAAAGLKI0xxoIAABgGRUIAAAM2IVhjgABAIABiyjN0cIAAACWUYEAAMCAFoY5AgQAAAbswjBHCwMAAFhGBQIAAAM3iyhNESAAADAgPpijhQEAACyjAgEAgAG7MMwRIAAAMCBAmCNAAABgwJMozbEGAgAAWEYFAgAAA1oY5ggQAAAY8CRKc7QwAACAZVQgAAAwYBGlOQIEAAAGrIEwRwsDAABYRgUCAAADWhjmCBAAABjQwjBHCwMAAFhGBQIAAAOeA2GOAAEAgIGbNRCmCBAAABhQgTDHGggAAGAZFQgAAAxoYZgjQAAAYEALwxwtDAAAYBkVCAAADGhhmCNAAABgQAvDHC0MAABgGRUIAAAMaGGYI0AAAGBAC8McLQwAAGqJSZMmKSAgwOdo06aN9/q5c+eUkpKiG2+8UQ0aNFC/fv1UWFjoc4+CggL16dNH9erVU1RUlMaOHauKiopqnysVCAAADDwet99+9q233qpPPvnE+zo4+Ptf1WPGjFFGRoaWLVum8PBwjRw5Ug888IA+//xzSVJlZaX69Okju92uDRs26PDhwxo0aJBCQkL00ksvVes8CRAAABi4/djCCA4Olt1uv+R8cXGx3nnnHS1evFh33323JOndd99V27ZttXHjRnXp0kVr1qzRV199pU8++UTR0dHq1KmTXnjhBY0fP16TJk1SaGhotc2TFgYAAAYej6faDpfLpZKSEp/D5XJd8Wd//fXXio2NVcuWLTVgwAAVFBRIknJzc1VeXq7ExETv2DZt2qhZs2bKycmRJOXk5Kh9+/aKjo72jklOTlZJSYny8/Or9e+IAAEAQA1KT09XeHi4z5Genn7ZsQkJCZo/f75WrVqlOXPm6MCBA+ratatOnTolp9Op0NBQRURE+LwnOjpaTqdTkuR0On3Cw4XrF65VJ1oYAAAYVGcLIy0tTampqT7nbDbbZcf27t3b++cOHTooISFBzZs319KlS1W3bt1qm1N1oAIBAIBBdbYwbDabwsLCfI4rBQijiIgI3XLLLdq7d6/sdrvKyspUVFTkM6awsNC7ZsJut1+yK+PC68utq/h3ECAAAKilTp8+rX379ikmJkbx8fEKCQlRVlaW9/ru3btVUFAgh8MhSXI4HNq+fbuOHDniHZOZmamwsDDFxcVV69xoYQAAYOCvJ1E+/fTTuu+++9S8eXMdOnRIzz33nIKCgvTwww8rPDxcQ4cOVWpqqiIjIxUWFqZRo0bJ4XCoS5cukqSkpCTFxcVp4MCBmjp1qpxOpyZMmKCUlJQqVz2qigABAICBv55E+e233+rhhx/W8ePH1bhxY/3iF7/Qxo0b1bhxY0nSa6+9psDAQPXr108ul0vJycmaPXu29/1BQUFauXKlRowYIYfDofr162vw4MGaPHlytc81wOOpHQ/8Dg79mb+nANQ6M6N7+HsKQK00/ODCGr2/PaJttd3LWbSz2u5Vm1CBAADAoJb8/9a1GgECAAADfz6J8nrBLgwAAGAZFQgAAAxoYZgjQAAAYOCvbZzXEwIEAAAGVCDMsQYCAABYRgUCAAADdmGYI0AAAGBAC8McLQwAAGAZFQgAAAzYhWGOAAEAgIG/vkzrekILAwAAWEYFAgAAA1oY5ggQAAAYsAvDHC0MAABgGRUIAAAMWERpjgABAIABLQxzBAgAAAwIEOZYAwEAACyjAgEAgAH1B3MBHuo0uIjL5VJ6errS0tJks9n8PR2gVuDfBXApAgR8lJSUKDw8XMXFxQoLC/P3dIBagX8XwKVYAwEAACwjQAAAAMsIEAAAwDICBHzYbDY999xzLBQDLsK/C+BSLKIEAACWUYEAAACWESAAAIBlBAgAAGAZAQIAAFhGgIDXrFmzdNNNN6lOnTpKSEjQ5s2b/T0lwK+ys7N13333KTY2VgEBAVqxYoW/pwTUGgQISJKWLFmi1NRUPffcc/rnP/+pjh07Kjk5WUeOHPH31AC/KS0tVceOHTVr1ix/TwWoddjGCUlSQkKCbr/9ds2cOVOS5Ha71bRpU40aNUrPPPOMn2cH+F9AQICWL1+uvn37+nsqQK1ABQIqKytTbm6uEhMTvecCAwOVmJionJwcP84MAFBbESCgY8eOqbKyUtHR0T7no6Oj5XQ6/TQrAEBtRoAAAACWESCgRo0aKSgoSIWFhT7nCwsLZbfb/TQrAEBtRoCAQkNDFR8fr6ysLO85t9utrKwsORwOP84MAFBbBft7AqgdUlNTNXjwYHXu3Fl33HGHXn/9dZWWluqxxx7z99QAvzl9+rT27t3rfX3gwAHl5eUpMjJSzZo18+PMAP9jGye8Zs6cqWnTpsnpdKpTp06aMWOGEhIS/D0twG/WrVunHj16XHJ+8ODBmj9//rWfEFCLECAAAIBlrIEAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABY9v8BZpTeTJIpQ7gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Confusion_matrix = confusion_matrix(test_targets, test_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(Confusion_matrix, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddafa47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Occupancy       0.91      0.44      0.59      5880\n",
      "   Occupancy       0.30      0.84      0.44      1685\n",
      "\n",
      "    accuracy                           0.53      7565\n",
      "   macro avg       0.60      0.64      0.51      7565\n",
      "weighted avg       0.77      0.53      0.56      7565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Classification_report = classification_report(test_targets, test_preds, target_names=['No Occupancy', 'Occupancy'], zero_division=0)\n",
    "print(\"Classification Report:\\n\", Classification_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
