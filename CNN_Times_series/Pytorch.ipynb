{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff13fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5de074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I trained the CNN model in Keras framework already, I am going to build CNN in PyTorch framework to see, could I get better result.\n",
    "# I will use the same code structure for prepring data in here as in Keras notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b6a75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccebe953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Humidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CO2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Occupancy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weekend",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tod_sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tod_cos",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "febbe7e7-c741-414a-b20f-955db8904a92",
       "rows": [
        [
         "0",
         "23.18",
         "27.272",
         "721.25",
         "1",
         "0",
         "-0.9992290362407228",
         "-0.039259815759069"
        ],
        [
         "1",
         "23.15",
         "27.2675",
         "714.0",
         "1",
         "0",
         "-0.9992290362407228",
         "-0.039259815759069"
        ],
        [
         "2",
         "23.15",
         "27.245",
         "713.5",
         "1",
         "0",
         "-0.9995335908367128",
         "-0.0305385132098227"
        ],
        [
         "3",
         "23.15",
         "27.2",
         "708.25",
         "1",
         "0",
         "-0.9996573249755571",
         "-0.0261769483078734"
        ],
        [
         "4",
         "23.1",
         "27.2",
         "704.5",
         "1",
         "0",
         "-0.9997620270799092",
         "-0.0218148850345608"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>CO2</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>weekend</th>\n",
       "      <th>tod_sin</th>\n",
       "      <th>tod_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>721.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999229</td>\n",
       "      <td>-0.039260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>714.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999229</td>\n",
       "      <td>-0.039260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>713.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999534</td>\n",
       "      <td>-0.030539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>708.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999657</td>\n",
       "      <td>-0.026177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>704.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999762</td>\n",
       "      <td>-0.021815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity     CO2  Occupancy  weekend   tod_sin   tod_cos\n",
       "0        23.18   27.2720  721.25          1        0 -0.999229 -0.039260\n",
       "1        23.15   27.2675  714.00          1        0 -0.999229 -0.039260\n",
       "2        23.15   27.2450  713.50          1        0 -0.999534 -0.030539\n",
       "3        23.15   27.2000  708.25          1        0 -0.999657 -0.026177\n",
       "4        23.10   27.2000  704.50          1        0 -0.999762 -0.021815"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the DSs \n",
    "df_test = pd.read_csv('cleaned_datatest.csv')\n",
    "df_val = pd.read_csv('datavalidation.csv')\n",
    "df_train = pd.read_csv('datatraining.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3162e4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(df_train.duplicated().sum())\n",
    "print(df_val.duplicated().sum())\n",
    "print(df_test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a3c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a3d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8117, 6) (8117,)\n",
      "Val: (2663, 6) (2663,)\n",
      "Test: (9720, 6) (9720,)\n"
     ]
    }
   ],
   "source": [
    "# Preparing data for CNN model,\n",
    "target = 'Occupancy'\n",
    "features = [\"Temperature\", \"Humidity\", \"CO2\", \"weekend\", \"tod_sin\", \"tod_cos\"]\n",
    "\n",
    "X_train = df_train[features].values\n",
    "y_train = df_train[target].values.astype(int)\n",
    "\n",
    "X_val = df_val[features].values\n",
    "y_val = df_val[target].values.astype(int)\n",
    "\n",
    "X_test = df_test[features].values\n",
    "y_test = df_test[target].values.astype(int)\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Scaling the features, I will fit only the train  DS\n",
    "# Because the weekend is binary and tod_sin, tod_cos are already normialized, to -1 , 1. So I will Standardize the continuous features.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled[:, 0:3] = scaler.fit_transform(X_train_scaled[:, 0:3])\n",
    "\n",
    "# transforming val and test DS \n",
    "X_val_scaled[:, 0:3] = scaler.transform(X_val_scaled[:, 0:3])\n",
    "X_test_scaled[:, 0:3]= scaler.transform(X_test_scaled[:, 0:3])\n",
    "\n",
    "print(\"Train:\", X_train_scaled.shape, y_train.shape)\n",
    "print(\"Val:\", X_val_scaled.shape, y_val.shape)\n",
    "print(\"Test:\", X_test_scaled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153e0047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekend unique: [0. 1.]\n",
      "tod_sin min/max: -1.0 1.0\n",
      "tod_cos min/max: -1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Checking the weekend and tod_sin, tod_cos. \n",
    "print(\"weekend unique:\", np.unique(X_train_scaled[:,3]))\n",
    "print(\"tod_sin min/max:\", X_train_scaled[:,4].min(), X_train_scaled[:,4].max())\n",
    "print(\"tod_cos min/max:\", X_train_scaled[:,5].min(), X_train_scaled[:,5].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2edb1e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: (8057, 60, 6) (8057,)\n",
      "Val windows: (2603, 60, 6) (2603,)\n",
      "Test windows: (9660, 60, 6) (9660,)\n"
     ]
    }
   ],
   "source": [
    "# MAKING SEQUENCES:\n",
    "# The CNN model for time series, needs sequences as input \n",
    "# I will create windows of minutes that the model will predict right after the window, the next minute\n",
    "\n",
    "# Creating function\n",
    "\n",
    "window_size = 60\n",
    "step_ahead = 1\n",
    "def windows_time(X, y, window_size = None, step_ahead = None):\n",
    "   # I will creaate two lists for storing  features and the target\n",
    "   # The end should start the a window\n",
    "   X_windows = []\n",
    "   y_windows = []\n",
    "   last_start = len(X) - window_size - step_ahead + 1\n",
    "   for start in range(last_start):\n",
    "        end = start + window_size\n",
    "        X_windows.append(X[start:end])                  \n",
    "        y_windows.append(y[end + step_ahead - 1])      \n",
    "   return np.array(X_windows), np.array(y_windows)\n",
    "\n",
    "  \n",
    "X_train_window, y_train_window = windows_time(X_train_scaled, y_train, window_size, step_ahead)\n",
    "X_val_window, y_val_window = windows_time(X_val_scaled, y_val, window_size, step_ahead)\n",
    "X_test_window, y_test_window = windows_time(X_test_scaled, y_test, window_size, step_ahead)\n",
    "\n",
    "print(\"Train windows:\", X_train_window.shape, y_train_window.shape)\n",
    "print(\"Val windows:\", X_val_window.shape,y_val_window.shape)\n",
    "print(\"Test windows:\", X_test_window.shape, y_test_window.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b86ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_window, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_window, dtype=torch.long) \n",
    "X_val_tensor = torch.tensor(X_val_window, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_window, dtype=torch.long)\n",
    "X_test_tensor= torch.tensor(X_test_window, dtype=torch.float32)\n",
    "y_test_tensor= torch.tensor(y_test_window, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba580d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "504a9af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([64, 60, 6])\n",
      "Batch target shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# I nned to see shape of one batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    print(f\"Batch input shape: {X_batch.shape}\") \n",
    "    print(f\"Batch target shape: {y_batch.shape}\")\n",
    "    break  \n",
    "# In forward function, I will switch input shape and sequence lemght"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b82d6",
   "metadata": {},
   "source": [
    "<h2><center>CNN Architecture<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "680f1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am going to build 1D CNN for time series classification. Same issue here, the imbalanced rate is not same for each DS.\n",
    "# First I need to create a convolutional block class \n",
    "# Second, I am going to create the CNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4abd361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnvectionalBlocks(nn.Module):\n",
    "    def __init__(self, Input_channel, Output_channel, kernel_size=3, dropout_rate=0.15):\n",
    "        super().__init__()\n",
    "        # First convolutional layer:\n",
    "        # the constrcutor will have input channel, output channel, kernel size and dropout rate as parameters.\n",
    "        self.conv1 = nn.Conv1d(in_channels=Input_channel, out_channels=Output_channel, kernel_size=kernel_size, padding= kernel_size//2)\n",
    "        # Batch normalization:\n",
    "        self.bn1 = nn.BatchNorm1d(Output_channel)\n",
    "        self.drop = nn.Dropout1d(p=dropout_rate)\n",
    "\n",
    "# Operation function:\n",
    " # Extrating the local patters \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "    \n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # First convolutional block\n",
    "        self.conv_block1 = ConnvectionalBlocks(Input_channel=6, Output_channel=16, kernel_size=3, dropout_rate=0.1)\n",
    "        # Second convolutional block\n",
    "        self.conv_block2 = ConnvectionalBlocks(Input_channel=16, Output_channel= 16, kernel_size=3, dropout_rate=0.1)\n",
    "        # Max pooling, to halve the lengh\n",
    "        self.pool1  = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv_block3 = ConnvectionalBlocks(Input_channel=16, Output_channel=32, kernel_size=3, dropout_rate=0.15)\n",
    "        # Fourth convolutional block\n",
    "        self.conv_block4 = ConnvectionalBlocks(Input_channel=32, Output_channel=32, kernel_size=3, dropout_rate=0.15)\n",
    "        # second Max pooling\n",
    "        self.pool2  = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "        # Global average pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(32, 1)\n",
    "\n",
    "\n",
    "# Operation function:   \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.squeeze(-1)\n",
    "        logits = self.fc1(x)\n",
    "        return logits\n",
    "\n",
    "model = CNNModel().to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Sources :\n",
    "# https://medium.com/@ugamakelechi501/building-a-convolutional-neural-network-cnn-from-scratch-with-pytorch-eca3ffdcf2ff\n",
    "# https://www.dkneup.com/blog/cnn-time-series-forecasting-in-tensorflow-pytorch\n",
    "# https://medium.com/%40santi.pdp/how-pytorch-transposed-convs1d-work-a7adac63c4a5\n",
    "# For debugging, I used the Qwen3 Max model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c174a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = y_train \n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_np), y=y_np)\n",
    "one_weight = torch.tensor(class_weights[1], dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=one_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454a297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0002\n",
      "    maximize: False\n",
      "    weight_decay: 8e-05\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0003, weight_decay=0.00008)\n",
    "# If val loss does not improve for 5 epochs, lr is going to be cut by half\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3, mode='min')\n",
    "print('Optimizer:', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7871d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/300 - Train Loss: 0.7366 Val Loss: 0.5306, Prec: 0.737, Learning Rate: 0.000200\n",
      "Epoch  2/300 - Train Loss: 0.5014 Val Loss: 0.4322, Prec: 0.784, Learning Rate: 0.000200\n",
      "Epoch  3/300 - Train Loss: 0.4220 Val Loss: 0.3932, Prec: 0.824, Learning Rate: 0.000200\n",
      "Epoch  4/300 - Train Loss: 0.3628 Val Loss: 0.3493, Prec: 0.847, Learning Rate: 0.000200\n",
      "Epoch  5/300 - Train Loss: 0.3275 Val Loss: 0.3153, Prec: 0.863, Learning Rate: 0.000200\n",
      "Epoch  6/300 - Train Loss: 0.2918 Val Loss: 0.2922, Prec: 0.893, Learning Rate: 0.000200\n",
      "Epoch  7/300 - Train Loss: 0.2698 Val Loss: 0.2675, Prec: 0.907, Learning Rate: 0.000200\n",
      "Epoch  8/300 - Train Loss: 0.2442 Val Loss: 0.2496, Prec: 0.898, Learning Rate: 0.000200\n",
      "Epoch  9/300 - Train Loss: 0.2292 Val Loss: 0.2447, Prec: 0.904, Learning Rate: 0.000200\n",
      "Epoch 10/300 - Train Loss: 0.2148 Val Loss: 0.2223, Prec: 0.868, Learning Rate: 0.000200\n",
      "Epoch 11/300 - Train Loss: 0.2051 Val Loss: 0.2245, Prec: 0.885, Learning Rate: 0.000200\n",
      "Epoch 12/300 - Train Loss: 0.2175 Val Loss: 0.2212, Prec: 0.879, Learning Rate: 0.000200\n",
      "Epoch 13/300 - Train Loss: 0.2024 Val Loss: 0.2365, Prec: 0.845, Learning Rate: 0.000200\n",
      "Epoch 14/300 - Train Loss: 0.1897 Val Loss: 0.2059, Prec: 0.872, Learning Rate: 0.000200\n",
      "Epoch 15/300 - Train Loss: 0.1977 Val Loss: 0.2209, Prec: 0.876, Learning Rate: 0.000200\n",
      "Epoch 16/300 - Train Loss: 0.1831 Val Loss: 0.2090, Prec: 0.912, Learning Rate: 0.000200\n",
      "Epoch 17/300 - Train Loss: 0.1781 Val Loss: 0.2004, Prec: 0.868, Learning Rate: 0.000200\n",
      "Epoch 18/300 - Train Loss: 0.1776 Val Loss: 0.2070, Prec: 0.865, Learning Rate: 0.000200\n",
      "Epoch 19/300 - Train Loss: 0.1739 Val Loss: 0.1991, Prec: 0.918, Learning Rate: 0.000200\n",
      "Epoch 20/300 - Train Loss: 0.1682 Val Loss: 0.2065, Prec: 0.875, Learning Rate: 0.000200\n",
      "Epoch 21/300 - Train Loss: 0.1701 Val Loss: 0.1851, Prec: 0.884, Learning Rate: 0.000200\n",
      "Epoch 22/300 - Train Loss: 0.1607 Val Loss: 0.2041, Prec: 0.856, Learning Rate: 0.000200\n",
      "Epoch 23/300 - Train Loss: 0.1751 Val Loss: 0.2000, Prec: 0.876, Learning Rate: 0.000200\n",
      "Epoch 24/300 - Train Loss: 0.1585 Val Loss: 0.2092, Prec: 0.895, Learning Rate: 0.000200\n",
      "Epoch 25/300 - Train Loss: 0.1596 Val Loss: 0.1951, Prec: 0.934, Learning Rate: 0.000200\n",
      "Epoch 26/300 - Train Loss: 0.1602 Val Loss: 0.2145, Prec: 0.865, Learning Rate: 0.000100\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)            \n",
    "        loss = criterion(outputs.squeeze(1), y_batch.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        preds = (torch.sigmoid(outputs) >= 0.5).float() \n",
    "        correct += (preds.squeeze() == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    model.eval()  \n",
    "     \n",
    "    with torch.no_grad():  \n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits.squeeze(1), y_batch.float())\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "\n",
    "            probs = torch.sigmoid(logits.squeeze(1))\n",
    "            preds = (probs >= 0.5).to(torch.int64)\n",
    "\n",
    "\n",
    "            val_preds.extend(preds.tolist())\n",
    "            val_targets.extend(y_batch.tolist())\n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "\n",
    "\n",
    "    \n",
    "    # Converting predictions and targets to numpy for calculations\n",
    "    val_preds = np.array(val_preds)\n",
    "    val_targets = np.array(val_targets)\n",
    "    \n",
    "    val_prec = precision_score(val_targets, val_preds, pos_label=1.0, zero_division=0)\n",
    "    learning_rate = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{epochs} - \"f\"Train Loss: {train_loss:.4f} \"f\"Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Prec: {val_prec:.3f}, \"f\"Learning Rate: {learning_rate:.6f}\")\n",
    "    \n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        \n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "if patience_counter >= patience:\n",
    "    model.load_state_dict(best_model_state)\n",
    "#Source: https://docs.pytorch.org/tutorials/beginner/introyt/trainingyt.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b00613de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL AP (AUPRC): 0.9492\n",
      "Best VAL F1: 0.9405 at threshold=0.6932 (P=0.9048, R=0.9792)\n",
      "\n",
      "TEST confusion matrix (using VAL threshold):\n",
      "[[6863  805]\n",
      " [ 511 1481]]\n",
      "\n",
      "TEST report (using VAL threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Occupancy       0.93      0.90      0.91      7668\n",
      "   Occupancy       0.65      0.74      0.69      1992\n",
      "\n",
      "    accuracy                           0.86      9660\n",
      "   macro avg       0.79      0.82      0.80      9660\n",
      "weighted avg       0.87      0.86      0.87      9660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, classification_report, confusion_matrix\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict_probs(model, loader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_y = []\n",
    "    for Xb, yb in loader:\n",
    "        Xb = Xb.to(device)\n",
    "        logits = model(Xb).squeeze(1)              # (B,)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy() # numpy (B,)\n",
    "        all_probs.append(probs)\n",
    "        all_y.append(yb.cpu().numpy())\n",
    "    return np.concatenate(all_probs), np.concatenate(all_y).astype(int)\n",
    "\n",
    "# IMPORTANT: set shuffle=False for val/test loaders before doing this\n",
    "val_probs, val_y = predict_probs(model, val_loader, device)\n",
    "\n",
    "val_ap = average_precision_score(val_y, val_probs)\n",
    "p, r, thr = precision_recall_curve(val_y, val_probs)\n",
    "\n",
    "f1 = (2 * p * r) / (p + r + 1e-12)\n",
    "best_i = np.argmax(f1[:-1])          # thr has length len(p)-1\n",
    "best_thr = thr[best_i]\n",
    "\n",
    "print(f\"VAL AP (AUPRC): {val_ap:.4f}\")\n",
    "print(f\"Best VAL F1: {f1[best_i]:.4f} at threshold={best_thr:.4f} (P={p[best_i]:.4f}, R={r[best_i]:.4f})\")\n",
    "\n",
    "test_probs, test_y = predict_probs(model, test_loader, device)\n",
    "test_pred = (test_probs >= best_thr).astype(int)\n",
    "\n",
    "print(\"\\nTEST confusion matrix (using VAL threshold):\")\n",
    "print(confusion_matrix(test_y, test_pred))\n",
    "\n",
    "print(\"\\nTEST report (using VAL threshold):\")\n",
    "print(classification_report(test_y, test_pred, target_names=[\"No Occupancy\",\"Occupancy\"], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36093e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_targets = []\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits.squeeze(), y_batch.float())\n",
    "        probs = torch.sigmoid(logits.squeeze())\n",
    "        preds = (probs >= 0.5).to(torch.int64)\n",
    "        test_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        test_preds.extend(preds.tolist())\n",
    "        test_targets.extend(y_batch.tolist())\n",
    "test_preds = np.array(test_preds)\n",
    "test_targets = np.array(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf49ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Confusion_matrix = confusion_matrix(test_targets, test_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(Confusion_matrix, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddafa47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Occupancy       0.95      0.87      0.91      7668\n",
      "   Occupancy       0.63      0.82      0.71      1992\n",
      "\n",
      "    accuracy                           0.86      9660\n",
      "   macro avg       0.79      0.84      0.81      9660\n",
      "weighted avg       0.88      0.86      0.87      9660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Classification_report = classification_report(test_targets, test_preds, target_names=['No Occupancy', 'Occupancy'], zero_division=0)\n",
    "print(\"Classification Report:\\n\", Classification_report)\n",
    "\n",
    "# Even though I have calculated class weights, but still the model is biased towards the class occupancy.\n",
    "# The gap between traning and validation loss is big, because the distribution of Occupancy is different in each DS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
